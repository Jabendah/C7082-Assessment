{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jabendah/C7082-Assessment/blob/main/Object_Detection_Farm_Animals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MACHINE LEARNING AND ARTIFICIAL INTELIGENCE (C7082)**\n",
        "##**Farm Animal Detection usin YOLOv5**"
      ],
      "metadata": {
        "id": "bVVSpPpzzjkj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNveqeA1KXGy"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mountiing my drive to google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFL3Do3fz47G",
        "outputId": "49a49de2-54d1-4eff-abbb-4c469e812c0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w4j6mJvomEv",
        "outputId": "99839ffd-396a-467d-8812-208988b7329a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# checking presenting working directory\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone YOLOv5 from github\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHiRiEeVo-c1",
        "outputId": "8e3ed9fa-76c4-4dda-f889-c42947c72174"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14995, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 14995 (delta 2), reused 1 (delta 0), pack-reused 14989\u001b[K\n",
            "Receiving objects: 100% (14995/14995), 14.01 MiB | 4.47 MiB/s, done.\n",
            "Resolving deltas: 100% (10304/10304), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change pwd to 'yolov5'\n",
        "import os\n",
        "os.chdir('yolov5')"
      ],
      "metadata": {
        "id": "Qfxy4iESpEBR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvDNSILZoN9",
        "outputId": "0d0c4773-f9c8-4e84-e581-599a31ee59db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (4.7.0.68)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless) (1.21.6)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.5/46.5 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.5/138.5 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Setup complete. Using torch 1.13.0+cu116 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-python-headless\n",
        "%pip install -qr requirements.txt\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
        "\n",
        "# Some warnings okay as of 2022-01-28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yAi9hd-T4B"
      },
      "source": [
        "# Step 2: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **--rect** ONLY use is images are rectangle\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone Georgina's repo\n",
        "!git clone https://github.com/georginaanna/Implementing-YOLOv5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FncTDm4xpn5Y",
        "outputId": "42725046-8353-42aa-b350-1be1b927bff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Implementing-YOLOv5'...\n",
            "remote: Enumerating objects: 463, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 463 (delta 16), reused 17 (delta 9), pack-reused 429\u001b[K\n",
            "Receiving objects: 100% (463/463), 55.90 MiB | 23.62 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFNnxLJbq4J",
        "outputId": "81b21878-2cb7-41e8-bf4b-8de059a6fbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/Implementing-YOLOv5/yolo-files/coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 45.9MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 21.9MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/Implementing-YOLOv5/coco128/labels/train2017... 128 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 1849.56it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Implementing-YOLOv5/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 128/128 [00:00<00:00, 148.85it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/Implementing-YOLOv5/coco128/labels/train2017.cache... 128 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 128/128 [00:01<00:00, 76.98it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.18 anchors/target, 0.977 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 16 of 929 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 927 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6614: 100% 1000/1000 [00:00<00:00, 1984.71it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9860 best possible recall, 3.81 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.265/0.663-mean/best, past_thr=0.474-mean: 10,13, 28,16, 34,44, 83,57, 64,110, 90,192, 175,152, 248,236, 396,272\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      1.69G    0.08146    0.05932    0.02409        231        416: 100% 8/8 [00:05<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.68it/s]\n",
            "                   all        128        929      0.359      0.501      0.439      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      2.08G    0.06366    0.05941    0.02596        200        416: 100% 8/8 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.01it/s]\n",
            "                   all        128        929      0.483      0.599      0.581      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      2.08G    0.05347    0.05819    0.02372        216        416: 100% 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.89it/s]\n",
            "                   all        128        929      0.571      0.584      0.627       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      2.08G    0.05207    0.05375    0.02263        210        416: 100% 8/8 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.74it/s]\n",
            "                   all        128        929      0.625      0.616      0.675      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      2.08G    0.04883    0.05598    0.02077        248        416: 100% 8/8 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.80it/s]\n",
            "                   all        128        929      0.708      0.623      0.695      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      2.08G     0.0477    0.05317    0.01889        297        416: 100% 8/8 [00:01<00:00,  4.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.51it/s]\n",
            "                   all        128        929      0.733      0.627      0.711      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      2.08G     0.0471    0.04743    0.01637        161        416: 100% 8/8 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.68it/s]\n",
            "                   all        128        929      0.684      0.669      0.726      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      2.08G    0.04632    0.04889    0.01647        157        416: 100% 8/8 [00:01<00:00,  4.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.78it/s]\n",
            "                   all        128        929      0.735      0.679      0.726      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      2.08G    0.04807    0.04639     0.0143        188        416: 100% 8/8 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.16it/s]\n",
            "                   all        128        929      0.744      0.638      0.717      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      2.08G    0.04771    0.04705    0.01661        184        416: 100% 8/8 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.14it/s]\n",
            "                   all        128        929      0.721      0.682      0.734      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      2.08G    0.04525    0.04842     0.0146        203        416: 100% 8/8 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.05it/s]\n",
            "                   all        128        929      0.626      0.697      0.716      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      2.08G     0.0502      0.047    0.01602        233        416: 100% 8/8 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.11it/s]\n",
            "                   all        128        929      0.646      0.686      0.717      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      2.08G    0.04623    0.04593    0.01531        233        416: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.19it/s]\n",
            "                   all        128        929      0.656      0.688      0.728      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      2.08G     0.0445    0.04409    0.01564        181        416: 100% 8/8 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.13it/s]\n",
            "                   all        128        929      0.723      0.685      0.758      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      2.08G    0.04643    0.04721    0.01538        217        416: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.05it/s]\n",
            "                   all        128        929      0.723      0.721      0.769      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      2.08G    0.04482    0.04597    0.01422        262        416: 100% 8/8 [00:01<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.16it/s]\n",
            "                   all        128        929      0.779      0.707      0.778      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      2.08G     0.0421     0.0468     0.0123        242        416: 100% 8/8 [00:01<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.20it/s]\n",
            "                   all        128        929      0.778      0.718      0.777      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      2.08G    0.04114    0.04157     0.0129        200        416: 100% 8/8 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.15it/s]\n",
            "                   all        128        929       0.79      0.725       0.78      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      2.08G    0.03979    0.04218    0.01395        147        416: 100% 8/8 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  4.00it/s]\n",
            "                   all        128        929      0.793      0.724      0.784      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      2.08G    0.04205    0.04252    0.01209        204        416: 100% 8/8 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.20it/s]\n",
            "                   all        128        929       0.82      0.731      0.795      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      2.08G    0.04052    0.04069    0.01232        206        416: 100% 8/8 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.11it/s]\n",
            "                   all        128        929       0.82      0.729      0.797      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      2.08G    0.03892    0.04535    0.01372        197        416: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.05it/s]\n",
            "                   all        128        929       0.82      0.729      0.801      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      2.08G    0.03971    0.04283    0.01158        220        416: 100% 8/8 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.13it/s]\n",
            "                   all        128        929      0.859      0.719       0.81      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      2.08G    0.03869    0.04373    0.01231        240        416: 100% 8/8 [00:01<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.98it/s]\n",
            "                   all        128        929      0.825      0.759      0.814       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      2.08G    0.03978    0.04368    0.01069        252        416: 100% 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.17it/s]\n",
            "                   all        128        929      0.841      0.767      0.823       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      2.08G    0.03804    0.03926    0.01219        169        416: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.33it/s]\n",
            "                   all        128        929      0.832      0.777      0.826      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      2.08G    0.03786    0.04321    0.01027        218        416: 100% 8/8 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.99it/s]\n",
            "                   all        128        929      0.834       0.77      0.818      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      2.08G    0.03656    0.04329   0.009469        197        416: 100% 8/8 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.01it/s]\n",
            "                   all        128        929      0.837      0.774      0.823      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      2.08G    0.03654    0.03985    0.01041        228        416: 100% 8/8 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:00<00:00,  4.16it/s]\n",
            "                   all        128        929      0.849      0.776      0.825      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      2.08G    0.03665    0.03967    0.01053        197        416: 100% 8/8 [00:01<00:00,  4.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  3.70it/s]\n",
            "                   all        128        929      0.843      0.773      0.826      0.579\n",
            "\n",
            "30 epochs completed in 0.029 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.7MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.7MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.14it/s]\n",
            "                   all        128        929      0.843      0.773      0.826      0.579\n",
            "                person        128        254      0.956      0.693      0.806      0.548\n",
            "               bicycle        128          6          1      0.506      0.738      0.406\n",
            "                   car        128         46      0.875      0.326      0.482      0.225\n",
            "            motorcycle        128          5      0.921          1      0.995      0.879\n",
            "              airplane        128          6      0.944          1      0.995      0.819\n",
            "                   bus        128          7      0.916      0.714      0.837      0.645\n",
            "                 train        128          3      0.873          1      0.995      0.732\n",
            "                 truck        128         12      0.727        0.5      0.588      0.381\n",
            "                  boat        128          6      0.775      0.585      0.656      0.361\n",
            "         traffic light        128         14      0.633      0.286      0.302      0.202\n",
            "             stop sign        128          2      0.728          1      0.995      0.821\n",
            "                 bench        128          9      0.989      0.889      0.968      0.601\n",
            "                  bird        128         16      0.976          1      0.995       0.69\n",
            "                   cat        128          4      0.932          1      0.995       0.83\n",
            "                   dog        128          9          1       0.98      0.995       0.77\n",
            "                 horse        128          2      0.797          1      0.995      0.846\n",
            "              elephant        128         17      0.965      0.941      0.947      0.744\n",
            "                  bear        128          1       0.76          1      0.995      0.995\n",
            "                 zebra        128          4      0.911          1      0.995      0.844\n",
            "               giraffe        128          9      0.956          1      0.995      0.789\n",
            "              backpack        128          6      0.737      0.667      0.695      0.337\n",
            "              umbrella        128         18      0.906      0.889      0.961      0.574\n",
            "               handbag        128         19      0.747      0.311      0.467       0.29\n",
            "                   tie        128          7          1      0.681      0.728        0.4\n",
            "              suitcase        128          4      0.848          1      0.995      0.673\n",
            "               frisbee        128          5      0.898        0.8        0.8      0.654\n",
            "                  skis        128          1      0.803          1      0.995      0.597\n",
            "             snowboard        128          7      0.808      0.714      0.808      0.502\n",
            "           sports ball        128          6          1      0.369        0.5      0.219\n",
            "                  kite        128         10      0.609        0.4      0.485        0.2\n",
            "          baseball bat        128          4      0.733      0.698      0.622      0.246\n",
            "        baseball glove        128          7      0.744      0.429      0.395      0.214\n",
            "            skateboard        128          5      0.897        0.8      0.797      0.608\n",
            "         tennis racket        128          7      0.715      0.571      0.648      0.384\n",
            "                bottle        128         18          1      0.322      0.687      0.371\n",
            "            wine glass        128         16      0.924      0.758      0.849      0.373\n",
            "                   cup        128         36      0.923       0.75      0.899      0.522\n",
            "                  fork        128          6      0.794      0.667      0.744      0.453\n",
            "                 knife        128         16      0.626      0.438      0.451      0.155\n",
            "                 spoon        128         22      0.823      0.455       0.58      0.305\n",
            "                  bowl        128         28       0.97      0.786      0.792      0.643\n",
            "                banana        128          1      0.475          1      0.995      0.796\n",
            "              sandwich        128          2      0.827          1      0.995      0.647\n",
            "                orange        128          4      0.797          1      0.995      0.615\n",
            "              broccoli        128         11      0.709      0.364      0.572      0.416\n",
            "                carrot        128         24      0.899      0.743      0.862      0.537\n",
            "               hot dog        128          2      0.824          1      0.995      0.945\n",
            "                 pizza        128          5          1      0.789      0.995      0.807\n",
            "                 donut        128         14      0.929      0.934       0.99      0.837\n",
            "                  cake        128          4      0.867          1      0.995      0.871\n",
            "                 chair        128         35       0.85       0.65       0.79      0.525\n",
            "                 couch        128          6      0.907          1      0.995      0.721\n",
            "          potted plant        128         14       0.83          1      0.986      0.634\n",
            "                   bed        128          3      0.877          1      0.995      0.897\n",
            "          dining table        128         13      0.903      0.718      0.828      0.627\n",
            "                toilet        128          2      0.838          1      0.995      0.846\n",
            "                    tv        128          2      0.826          1      0.995      0.895\n",
            "                laptop        128          3          1      0.641      0.913      0.509\n",
            "                 mouse        128          2      0.716        0.5      0.606      0.204\n",
            "                remote        128          8      0.916      0.625      0.668      0.394\n",
            "            cell phone        128          8      0.599        0.5        0.5      0.321\n",
            "             microwave        128          3      0.865          1      0.995      0.863\n",
            "                  oven        128          5      0.794        0.8      0.898      0.731\n",
            "                  sink        128          6      0.892      0.667       0.67      0.469\n",
            "          refrigerator        128          5       0.85          1      0.995      0.716\n",
            "                  book        128         29      0.633      0.172      0.368      0.219\n",
            "                 clock        128          9          1       0.94      0.995      0.735\n",
            "                  vase        128          2      0.795          1      0.995      0.895\n",
            "              scissors        128          1      0.529          1      0.995      0.255\n",
            "            teddy bear        128         21      0.849      0.905       0.93      0.651\n",
            "            toothbrush        128          5      0.885          1      0.995      0.697\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# training the coco128 dataset\n",
        "!python train.py --img 416 --batch 16 --epochs 30 --data /content/yolov5/Implementing-YOLOv5/yolo-files/coco128.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS7lPFFTomE1"
      },
      "source": [
        "# Step 3: test test test\n",
        "Now test your model on some test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWjjiBcic3Vz",
        "outputId": "a9bd7ce4-0e35-42a9-c326-b9b49b45e793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/yolov5/Implementing-YOLOv5/coco128/test, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "image 1/4 /content/yolov5/Implementing-YOLOv5/coco128/test/Cthulhu_and_R'lyeh.jpg: 416x320 1 zebra, 12.5ms\n",
            "image 2/4 /content/yolov5/Implementing-YOLOv5/coco128/test/test1.jpg: 288x416 1 bear, 17.8ms\n",
            "image 3/4 /content/yolov5/Implementing-YOLOv5/coco128/test/test2.jpg: 288x416 1 elephant, 9.4ms\n",
            "image 4/4 /content/yolov5/Implementing-YOLOv5/coco128/test/test3.jpg: 416x288 1 cat, 14.0ms\n",
            "Speed: 0.4ms pre-process, 13.4ms inference, 1.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# make the \"exp\" from the trained model to test \n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source /content/yolov5/Implementing-YOLOv5/coco128/test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Train My Model\n",
        "Dowmload my data and train"
      ],
      "metadata": {
        "id": "Or5QZuZ5rB3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# my data\n",
        "!pip install roboflow\n",
        "\n",
        " \n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Brd3ELP5PCWCmywMoJzI\")\n",
        "project = rf.workspace(\"213221\").project(\"21322100\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzyi9avhrTMO",
        "outputId": "87ea2eb0-6b84-4b11-b927-5ac8afb1271e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.8/dist-packages (0.2.25)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.26.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.7.0.68)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.21.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in 21322100-1 to yolov5pytorch: 100% [27770911 / 27770911] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to 21322100-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 969/969 [00:00<00:00, 2035.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Train my model\n",
        "Using 30 epochs and 16 batches as to compare with the coco128"
      ],
      "metadata": {
        "id": "iZKi8Ci-rzC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training path \n",
        "!python train.py --img 416 --batch 16 --epochs 30 --data /content/yolov5/21322100-1/data.yaml --weights yolov5s.pt --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8eVUAEzr4T5",
        "outputId": "5b1da126-8d0c-425a-cbf4-a94d80f0bcdc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/21322100-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/21322100-1/train/labels... 400 images, 0 backgrounds, 0 corrupt: 100% 400/400 [00:00<00:00, 1697.91it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/21322100-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 400/400 [00:02<00:00, 173.75it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/21322100-1/test/labels... 480 images, 0 backgrounds, 0 corrupt: 100% 480/480 [00:00<00:00, 937.72it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/21322100-1/test/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB ram): 100% 480/480 [00:04<00:00, 107.38it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      1.71G     0.1046    0.02425    0.06242         44        416: 100% 25/25 [00:06<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:04<00:00,  3.74it/s]\n",
            "                   all        480        803     0.0041      0.752     0.0406     0.0133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      2.07G    0.07544    0.02796    0.05351         45        416: 100% 25/25 [00:04<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.20it/s]\n",
            "                   all        480        803      0.205      0.388      0.183      0.074\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      2.07G    0.06619     0.0238    0.04982         55        416: 100% 25/25 [00:04<00:00,  5.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.56it/s]\n",
            "                   all        480        803      0.227      0.283      0.213     0.0837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      2.07G    0.06168    0.02395    0.04394         41        416: 100% 25/25 [00:04<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.47it/s]\n",
            "                   all        480        803      0.367      0.389      0.303      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      2.07G    0.05975    0.02093     0.0418         43        416: 100% 25/25 [00:04<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.53it/s]\n",
            "                   all        480        803      0.267      0.392      0.279      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      2.07G    0.05608    0.01975    0.03666         48        416: 100% 25/25 [00:04<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.64it/s]\n",
            "                   all        480        803      0.318      0.431      0.301      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      2.07G    0.05357    0.01997    0.03551         48        416: 100% 25/25 [00:04<00:00,  5.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.70it/s]\n",
            "                   all        480        803      0.597      0.515      0.495      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      2.07G    0.05113    0.02009    0.03466         40        416: 100% 25/25 [00:04<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.68it/s]\n",
            "                   all        480        803      0.666      0.544       0.59      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      2.07G    0.04961    0.01911    0.03197         43        416: 100% 25/25 [00:04<00:00,  5.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:04<00:00,  3.35it/s]\n",
            "                   all        480        803      0.526      0.567      0.561       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      2.07G    0.04511    0.01929    0.03066         54        416: 100% 25/25 [00:04<00:00,  5.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.69it/s]\n",
            "                   all        480        803      0.475      0.654       0.58      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      2.07G    0.04735    0.01839      0.028         54        416: 100% 25/25 [00:04<00:00,  5.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.63it/s]\n",
            "                   all        480        803      0.662      0.596      0.657      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      2.07G    0.04363    0.01764     0.0281         50        416: 100% 25/25 [00:04<00:00,  5.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.83it/s]\n",
            "                   all        480        803      0.579      0.686      0.653      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      2.07G    0.04369    0.01847    0.02676         49        416: 100% 25/25 [00:04<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.55it/s]\n",
            "                   all        480        803      0.759       0.65      0.739      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      2.07G    0.04286    0.01885     0.0241         45        416: 100% 25/25 [00:04<00:00,  5.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.80it/s]\n",
            "                   all        480        803      0.642      0.654       0.69      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      2.07G     0.0409    0.01825    0.02299         47        416: 100% 25/25 [00:04<00:00,  5.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.73it/s]\n",
            "                   all        480        803        0.7      0.716       0.74      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      2.07G    0.03958    0.01788     0.0245         65        416: 100% 25/25 [00:04<00:00,  5.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.73it/s]\n",
            "                   all        480        803      0.786      0.689      0.779      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      2.07G    0.03891    0.01797    0.02082         64        416: 100% 25/25 [00:04<00:00,  5.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.68it/s]\n",
            "                   all        480        803      0.754       0.74      0.795      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      2.07G    0.03801    0.01703    0.02312         56        416: 100% 25/25 [00:04<00:00,  5.98it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.79it/s]\n",
            "                   all        480        803      0.757      0.681      0.758      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      2.07G     0.0366    0.01681    0.02181         63        416: 100% 25/25 [00:04<00:00,  6.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.58it/s]\n",
            "                   all        480        803      0.795      0.758       0.83      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      2.07G    0.03776    0.01578    0.01921         58        416: 100% 25/25 [00:04<00:00,  5.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.70it/s]\n",
            "                   all        480        803      0.783      0.745      0.826      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      2.07G     0.0367    0.01739    0.02037         34        416: 100% 25/25 [00:04<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.70it/s]\n",
            "                   all        480        803      0.796      0.772      0.833      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      2.07G    0.03556    0.01661    0.01853         53        416: 100% 25/25 [00:04<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.69it/s]\n",
            "                   all        480        803      0.826      0.789       0.85      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      2.07G    0.03474    0.01785    0.01613         55        416: 100% 25/25 [00:04<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.65it/s]\n",
            "                   all        480        803        0.8       0.77      0.853      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      2.07G    0.03665    0.01621    0.01581         64        416: 100% 25/25 [00:04<00:00,  5.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.75it/s]\n",
            "                   all        480        803      0.839      0.821      0.885      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      2.07G    0.03331    0.01649    0.01642         51        416: 100% 25/25 [00:04<00:00,  5.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.60it/s]\n",
            "                   all        480        803      0.865      0.818      0.881       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      2.07G    0.03228    0.01745    0.01561         59        416: 100% 25/25 [00:04<00:00,  5.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.73it/s]\n",
            "                   all        480        803      0.863      0.812      0.877      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      2.07G    0.03136    0.01559    0.01491         39        416: 100% 25/25 [00:04<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.73it/s]\n",
            "                   all        480        803      0.878      0.769      0.853      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      2.07G    0.03184     0.0155    0.01536         41        416: 100% 25/25 [00:04<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.71it/s]\n",
            "                   all        480        803      0.908      0.842      0.893      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      2.07G    0.02997    0.01609    0.01376         51        416: 100% 25/25 [00:04<00:00,  5.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.73it/s]\n",
            "                   all        480        803      0.907      0.851      0.905      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      2.07G    0.03091    0.01629    0.01388         50        416: 100% 25/25 [00:04<00:00,  5.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:03<00:00,  4.62it/s]\n",
            "                   all        480        803      0.938      0.845      0.908      0.657\n",
            "\n",
            "30 epochs completed in 0.067 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:05<00:00,  2.89it/s]\n",
            "                   all        480        803      0.939      0.842      0.908      0.656\n",
            "                  Bear        480         59      0.886      0.932      0.933      0.749\n",
            "                   Cat        480         92      0.926      0.819      0.902      0.567\n",
            "                Cattle        480        135      0.955      0.896      0.958      0.657\n",
            "               Chicken        480         89      0.971      0.762      0.811      0.607\n",
            "                   Dog        480        106       0.95      0.904      0.951      0.682\n",
            "              Elephant        480         86          1      0.925       0.97       0.77\n",
            "                Person        480        156      0.886      0.769      0.829      0.538\n",
            "                   Pig        480         80      0.935      0.724      0.911      0.678\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Test\n",
        "Test the model with the test folder on my 21322100-1 dataset"
      ],
      "metadata": {
        "id": "gZjplDcDvdpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp2/weights/best.pt --img 416 --conf 0.1 --source /content/yolov5/21322100-1/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgU_TbVZvIPO",
        "outputId": "5427cf52-af09-4358-f59a-ff43ffe14ce6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp2/weights/best.pt'], source=/content/yolov5/21322100-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/80 /content/yolov5/21322100-1/test/images/20221023_140514_jpg.rf.8b5bf371e23b3fe491ce05f48b662d27.jpg: 416x416 3 Persons, 8.8ms\n",
            "image 2/80 /content/yolov5/21322100-1/test/images/alexander-krivitskiy-tSX6E9UextA-unsplash_jpg.rf.cf87c8c0f5d7066f99d4f3a0d0bb48ae.jpg: 416x416 1 Person, 9.6ms\n",
            "image 3/80 /content/yolov5/21322100-1/test/images/anmol-kerketta-QrOaXkjqmA-unsplash_jpg.rf.0351c81b96b9db1281de92d9e05d225a.jpg: 416x416 3 Cattles, 2 Persons, 8.8ms\n",
            "image 4/80 /content/yolov5/21322100-1/test/images/becca-_r6w0R6SueQ-unsplash_jpg.rf.3678b452df112264dc0b37eae89f4996.jpg: 416x416 1 Bear, 8.6ms\n",
            "image 5/80 /content/yolov5/21322100-1/test/images/cat_100_jpg.rf.37a5d055ee290eca8d56160bcc3e6f04.jpg: 416x416 1 Cat, 8.7ms\n",
            "image 6/80 /content/yolov5/21322100-1/test/images/charlesdeluvio-Mv9hjnEUHR4-unsplash_jpg.rf.6f999711dc619c68a2395ade979fb412.jpg: 416x416 1 Dog, 9.7ms\n",
            "image 7/80 /content/yolov5/21322100-1/test/images/danie-franco-A6O7pgc7vHg-unsplash_jpg.rf.94628720c4e4ab5bcca134c673b56a41.jpg: 416x416 1 Person, 8.4ms\n",
            "image 8/80 /content/yolov5/21322100-1/test/images/debbie-molle-6DSID8Ey9-U-unsplash_jpg.rf.b56dfb25e6eae4eb2e93d0e4a18aa719.jpg: 416x416 1 Bear, 12.4ms\n",
            "image 9/80 /content/yolov5/21322100-1/test/images/deon-de-villiers-7HRHhcueqZ8-unsplash_jpg.rf.f5d19c70ab91d2d458253563f9132c71.jpg: 416x416 4 Cattles, 4 Elephants, 2 Pigs, 8.6ms\n",
            "image 10/80 /content/yolov5/21322100-1/test/images/dog_54_jpg.rf.1b3a36fc8f1cef43cbfb1ebcfae0b392.jpg: 416x416 1 Dog, 2 Persons, 8.8ms\n",
            "image 11/80 /content/yolov5/21322100-1/test/images/dog_78_jpg.rf.ad78df5fa2fd9e1cbc3c25b3907e0a9b.jpg: 416x416 1 Dog, 8.6ms\n",
            "image 12/80 /content/yolov5/21322100-1/test/images/dusan-veverkolog-ETsFvMEBKTw-unsplash_jpg.rf.af46abd924bba409482c8f8a970a657b.jpg: 416x416 1 Bear, 8.9ms\n",
            "image 13/80 /content/yolov5/21322100-1/test/images/eliott-reyna-jCEpN62oWL4-unsplash_jpg.rf.85cf78c4e4b34303947ea3f5a55039b5.jpg: 416x416 7 Persons, 12.5ms\n",
            "image 14/80 /content/yolov5/21322100-1/test/images/ellicia-IgdVdJCmzf4-unsplash_jpg.rf.f8b8e140b5b4362d1c6afd8af8ca885c.jpg: 416x416 1 Bear, 2 Pigs, 8.6ms\n",
            "image 15/80 /content/yolov5/21322100-1/test/images/flouffy-7hEXd9kYPCY-unsplash_jpg.rf.a8496866dd6f4e7c9494453c445e33f0.jpg: 416x416 1 Person, 8.8ms\n",
            "image 16/80 /content/yolov5/21322100-1/test/images/gemma-chua-tran-Ftvf4VbVbDE-unsplash_jpg.rf.63e45ca610945c605433fc3c62f05d39.jpg: 416x416 1 Person, 9.5ms\n",
            "image 17/80 /content/yolov5/21322100-1/test/images/hadis-safari-A7rkoSFjrG0-unsplash_jpg.rf.038cd34896f4536d51ba7153fd30a1ea.jpg: 416x416 2 Persons, 9.7ms\n",
            "image 18/80 /content/yolov5/21322100-1/test/images/hans-jurgen-mager-Opd59VdnPn0-unsplash_jpg.rf.ed5bde8aeb9e894e8cad33fc1a49fc39.jpg: 416x416 1 Bear, 9.6ms\n",
            "image 19/80 /content/yolov5/21322100-1/test/images/hyunwon-jang-LYK3ksSQyeo-unsplash_jpg.rf.a8919fed6bf75b009fc84f0547611195.jpg: 416x416 1 Cattle, 1 Dog, 9.5ms\n",
            "image 20/80 /content/yolov5/21322100-1/test/images/ilse-orsel-vmFEBIEz0hQ-unsplash_jpg.rf.9a4736f9b1cbb244633fc01cdbaefa97.jpg: 416x416 2 Cats, 10.1ms\n",
            "image 21/80 /content/yolov5/21322100-1/test/images/jean-wimmerlin-Ypv-kNjcnDA-unsplash_jpg.rf.060e85699e4fd10c87b7f10d049fe6e0.jpg: 416x416 1 Elephant, 9.6ms\n",
            "image 22/80 /content/yolov5/21322100-1/test/images/jessica-weiller-kZ8dyUT0h30-unsplash_jpg.rf.65afe9638114a15a988fdf9fba189ebe.jpg: 416x416 1 Bear, 9.5ms\n",
            "image 23/80 /content/yolov5/21322100-1/test/images/john-matychuk-jDRTl-w5jtY-unsplash_jpg.rf.fbdb07d243626a7899f43d071075ddda.jpg: 416x416 2 Elephants, 9.4ms\n",
            "image 24/80 /content/yolov5/21322100-1/test/images/jonny-gios-VYQRj0e54u8-unsplash_jpg.rf.19004b6dc593345d2a6481bffc2502c1.jpg: 416x416 1 Chicken, 10.1ms\n",
            "image 25/80 /content/yolov5/21322100-1/test/images/jopeel-quimpo-FBkgT8Y4mLw-unsplash_jpg.rf.8701dc5143cec5bf1fe8ef960b3c22c7.jpg: 416x416 1 Chicken, 8.8ms\n",
            "image 26/80 /content/yolov5/21322100-1/test/images/julien-mussard-OApeDBma_zY-unsplash_jpg.rf.34636742e0e2f7658b45716fa5a55c0d.jpg: 416x416 1 Bear, 8.7ms\n",
            "image 27/80 /content/yolov5/21322100-1/test/images/karsten-winegeart-BJaqPaH6AGQ-unsplash_jpg.rf.ea5123803ee66bcfb6d5af91b4f3ab09.jpg: 416x416 1 Dog, 8.4ms\n",
            "image 28/80 /content/yolov5/21322100-1/test/images/karsten-winegeart-Qb7D1xw28Co-unsplash_jpg.rf.34ca61d415ab0d4f6c01362740a16f24.jpg: 416x416 1 Dog, 11.7ms\n",
            "image 29/80 /content/yolov5/21322100-1/test/images/kelly-e1u0YdAkh9k-unsplash_jpg.rf.d84194b06560ea492b4582fff3d1c6c8.jpg: 416x416 2 Dogs, 8.5ms\n",
            "image 30/80 /content/yolov5/21322100-1/test/images/kote-puerto-so5nsYDOdxw-unsplash_jpg.rf.7d4c38c695002b8bea91a1f21c49c7cb.jpg: 416x416 1 Cat, 9.5ms\n",
            "image 31/80 /content/yolov5/21322100-1/test/images/kyle-mackie-rIo3D0hnVAg-unsplash_jpg.rf.88df4905f1f61c06316768032fb4b96d.jpg: 416x416 6 Cattles, 8.4ms\n",
            "image 32/80 /content/yolov5/21322100-1/test/images/larry-costales-Ahf1ZmcKzgE-unsplash_jpg.rf.f88335097ce2201a2f6e9565a8af896e.jpg: 416x416 1 Cattle, 8.9ms\n",
            "image 33/80 /content/yolov5/21322100-1/test/images/lucrezia-carnelos-0liYTl4dJxk-unsplash_jpg.rf.cf22ce3ee73643410b07c3635759d3fb.jpg: 416x416 1 Dog, 1 Person, 8.5ms\n",
            "image 34/80 /content/yolov5/21322100-1/test/images/marek-piwnicki-PUVVsYJPh78-unsplash_jpg.rf.95ffaf9cb2945205312a35af01625b35.jpg: 416x416 4 Pigs, 8.6ms\n",
            "image 35/80 /content/yolov5/21322100-1/test/images/mathilda-khoo-vLR0YP_otCo-unsplash_jpg.rf.7bec4a1e035e73be9aad36d2e88274ef.jpg: 416x416 1 Person, 8.5ms\n",
            "image 36/80 /content/yolov5/21322100-1/test/images/matt-quinn-Q6-jv031muY-unsplash_jpg.rf.179e1cd8437e5355a5b5e8fa26e5030a.jpg: 416x416 15 Persons, 9.3ms\n",
            "image 37/80 /content/yolov5/21322100-1/test/images/matthew-spiteri-WfZ4WCuNtlg-unsplash_jpg.rf.00207cbec5f3067895bcb1b49d94e5f6.jpg: 416x416 3 Elephants, 8.6ms\n",
            "image 38/80 /content/yolov5/21322100-1/test/images/max-saeling-s3fOyTAOUUU-unsplash_jpg.rf.d06382cd7eb136b2b53bf16a3e60674c.jpg: 416x416 5 Cattles, 8.5ms\n",
            "image 39/80 /content/yolov5/21322100-1/test/images/megan-soule-xbVIg4Sjkc4-unsplash_jpg.rf.7540f4b60d6adf71e6642197813b3eb1.jpg: 416x416 1 Elephant, 1 Person, 8.3ms\n",
            "image 40/80 /content/yolov5/21322100-1/test/images/milk-tea-h7Dw2hF4e0A-unsplash_jpg.rf.55c72d4095796f4440d1bacd0d3acdfc.jpg: 416x416 1 Cat, 8.3ms\n",
            "image 41/80 /content/yolov5/21322100-1/test/images/mohammed-alzubidi-TZVYwkLDX1E-unsplash_jpg.rf.274795cac21b991d65cf1aeec8cdf140.jpg: 416x416 1 Cattle, 8.3ms\n",
            "image 42/80 /content/yolov5/21322100-1/test/images/nadi-whatisdelirium-fZ8uf_L52wg-unsplash_jpg.rf.048d91d1121171ef2a78fa7b4349315c.jpg: 416x416 1 Pig, 9.3ms\n",
            "image 43/80 /content/yolov5/21322100-1/test/images/nebojsa-ilic-w7QGY1ZNFds-unsplash_jpg.rf.229e1cd848bf6810a265b13bba366b41.jpg: 416x416 2 Bears, 1 Elephant, 2 Pigs, 8.4ms\n",
            "image 44/80 /content/yolov5/21322100-1/test/images/nicholas-green-nPz8akkUmDI-unsplash_jpg.rf.2b4141706259f43bbf4accdbbdc3eba2.jpg: 416x416 18 Persons, 8.6ms\n",
            "image 45/80 /content/yolov5/21322100-1/test/images/omar-lopez-T6zu4jFhVwg-unsplash_jpg.rf.abc4f162f20d153a3e748a820de7071c.jpg: 416x416 2 Cats, 12 Persons, 8.4ms\n",
            "image 46/80 /content/yolov5/21322100-1/test/images/patrick-pahlke-21iYB5pAtGg-unsplash_jpg.rf.f196ba531f0d1ce2ce1772f622b549ff.jpg: 416x416 1 Chicken, 2 Pigs, 8.3ms\n",
            "image 47/80 /content/yolov5/21322100-1/test/images/paul-szewczyk-fHLqRr2b7CU-unsplash_jpg.rf.499fa608f23bf63bc4607f3389fc19e9.jpg: 416x416 7 Cattles, 1 Person, 12.0ms\n",
            "image 48/80 /content/yolov5/21322100-1/test/images/qijin-xu-vQUXUHjyy8A-unsplash_jpg.rf.d02d785f40f429792840b65013c0c3f1.jpg: 416x416 1 Cat, 8.4ms\n",
            "image 49/80 /content/yolov5/21322100-1/test/images/raoul-droog-yMSecCHsIBc-unsplash_jpg.rf.1e1eab32da5bb356bed168df04ebc50a.jpg: 416x416 1 Bear, 1 Dog, 8.6ms\n",
            "image 50/80 /content/yolov5/21322100-1/test/images/remi-remino-E9kVmtiqqGE-unsplash_jpg.rf.9957264ed9e9f54b91fa812531c34a43.jpg: 416x416 1 Cat, 8.6ms\n",
            "image 51/80 /content/yolov5/21322100-1/test/images/richard-jacobs-8oenpCXktqQ-unsplash_jpg.rf.99981c1a76d2a00973e87c335f8f1d94.jpg: 416x416 1 Cattle, 3 Elephants, 13.7ms\n",
            "image 52/80 /content/yolov5/21322100-1/test/images/robert-bottman-IZiAUsTFZm4-unsplash_jpg.rf.4fbe21dc3012eeac9f5ef50595d78585.jpg: 416x416 3 Chickens, 1 Person, 8.2ms\n",
            "image 53/80 /content/yolov5/21322100-1/test/images/roberto-nickson-udjuFffdtWY-unsplash_jpg.rf.8aa467ddf1f21d0899c5ef324be28d5d.jpg: 416x416 1 Pig, 8.3ms\n",
            "image 54/80 /content/yolov5/21322100-1/test/images/sarah-halliday-IuaPUiQotdU-unsplash_jpg.rf.2f2942d90f2e537a3d9408bb37043caf.jpg: 416x416 1 Chicken, 8.7ms\n",
            "image 55/80 /content/yolov5/21322100-1/test/images/senjuti-kundu-JfolIjRnveY-unsplash_jpg.rf.42129051d455c3091b13c0b5b2ffcf28.jpg: 416x416 1 Chicken, 8.5ms\n",
            "image 56/80 /content/yolov5/21322100-1/test/images/serge-le-strat-g3QTR9n7hsg-unsplash_jpg.rf.51ade13804e100d75ad13e6d470d5f09.jpg: 416x416 5 Cattles, 8.2ms\n",
            "image 57/80 /content/yolov5/21322100-1/test/images/sergio-ortega-7ce10LAA9HE-unsplash_jpg.rf.e6a3d93e5bf79e685315d060079c426d.jpg: 416x416 5 Elephants, 9.0ms\n",
            "image 58/80 /content/yolov5/21322100-1/test/images/sherard-campbell-Mzy3CT69Tns-unsplash_jpg.rf.6241ed00c834de63e543a32c63efe3c4.jpg: 416x416 1 Dog, 9.4ms\n",
            "image 59/80 /content/yolov5/21322100-1/test/images/sherard-campbell-OmF9_5i2muo-unsplash_jpg.rf.234707d4c701a6de760e15a4a002714d.jpg: 416x416 1 Cattle, 9.5ms\n",
            "image 60/80 /content/yolov5/21322100-1/test/images/sikes-photos-FBVWVwbR5-w-unsplash_jpg.rf.706e5d84785a6967e2d96def4f6da058.jpg: 416x416 5 Cattles, 9.7ms\n",
            "image 61/80 /content/yolov5/21322100-1/test/images/sinval-carvalho-jTnSTGeXvNs-unsplash_jpg.rf.2a61b4c6784e6af5278e5cfbb04ce5f6.jpg: 416x416 1 Bear, 1 Pig, 9.4ms\n",
            "image 62/80 /content/yolov5/21322100-1/test/images/sippakorn-yamkasikorn-wWIK8hnESnY-unsplash_jpg.rf.3a7ae2b5d94df424ec40dd933b437943.jpg: 416x416 1 Chicken, 10.5ms\n",
            "image 63/80 /content/yolov5/21322100-1/test/images/steven-boesky-6GH00hMbjPI-unsplash_jpg.rf.9ce367e4f7f403c3226964d908e2fa9a.jpg: 416x416 1 Chicken, 14.5ms\n",
            "image 64/80 /content/yolov5/21322100-1/test/images/sutirta-budiman-Xm_d76KavOk-unsplash_jpg.rf.d59ccf57bce0a190ed7c42f697dea57c.jpg: 416x416 1 Elephant, 10.0ms\n",
            "image 65/80 /content/yolov5/21322100-1/test/images/taylor-kopel-WX4i1Jq_o0Y-unsplash_jpg.rf.d80441d39ead18e2bd6151cd64251c08.jpg: 416x416 1 Dog, 10.9ms\n",
            "image 66/80 /content/yolov5/21322100-1/test/images/thomas-iversen-4W8FgDVyUME-unsplash_jpg.rf.ae2543055732239de0f56a6f29bc2dd3.jpg: 416x416 4 Chickens, 1 Pig, 9.9ms\n",
            "image 67/80 /content/yolov5/21322100-1/test/images/thomas-lipke-KCyLa5xkoic-unsplash_jpg.rf.b0c7adcaf92416bff963d33047fb755e.jpg: 416x416 1 Bear, 9.3ms\n",
            "image 68/80 /content/yolov5/21322100-1/test/images/thomas-m-evans-mg2ACzid4fY-unsplash_jpg.rf.4403978d83ed0121c1726265c2ded413.jpg: 416x416 1 Cattle, 9.0ms\n",
            "image 69/80 /content/yolov5/21322100-1/test/images/victor-grabarczyk-2pbnDRhXc6Q-unsplash_jpg.rf.d0d713f089fc2d68e8bb6ab824fc2ad2.jpg: 416x416 1 Cattle, 1 Dog, 10.1ms\n",
            "image 70/80 /content/yolov5/21322100-1/test/images/vito-natale-avMIDf1WPCg-unsplash_jpg.rf.7a7c9682ca2533f20e353c4168c72f95.jpg: 416x416 1 Pig, 8.8ms\n",
            "image 71/80 /content/yolov5/21322100-1/test/images/wade-austin-ellis-FtuJIuBbUhI-unsplash_jpg.rf.6254154ad3a51815990360325eb1e5fc.jpg: 416x416 2 Persons, 8.4ms\n",
            "image 72/80 /content/yolov5/21322100-1/test/images/will-h-mcmahan-jM73872dy4Y-unsplash_jpg.rf.4ae7091b3f5206dbf3c6a69662b4a7f4.jpg: 416x416 3 Cattles, 2 Chickens, 8.5ms\n",
            "image 73/80 /content/yolov5/21322100-1/test/images/will-shirley-sbyEMIcFx34-unsplash_jpg.rf.7cbb09cc12737472ff76615841296f12.jpg: 416x416 1 Elephant, 9.7ms\n",
            "image 74/80 /content/yolov5/21322100-1/test/images/wolfgang-hasselmann-2zSkt52ELsk-unsplash_jpg.rf.30a3eb81f174566a2a3483629dc90364.jpg: 416x416 3 Elephants, 8.3ms\n",
            "image 75/80 /content/yolov5/21322100-1/test/images/wolfgang-hasselmann-W99CE3hOKf4-unsplash_jpg.rf.303c42e0e8a3314f3ed6c3f8d5ef0c0e.jpg: 416x416 1 Cattle, 8.2ms\n",
            "image 76/80 /content/yolov5/21322100-1/test/images/zdenek-machacek-PK94wCeXdjA-unsplash_jpg.rf.8535e87495c0ed8635bc42acec03a1af.jpg: 416x416 1 Bear, 8.4ms\n",
            "image 77/80 /content/yolov5/21322100-1/test/images/zdenek-machacek-hztya2tQqB8-unsplash_jpg.rf.a15db390eae3413edbd1a95d7483611e.jpg: 416x416 1 Bear, 11.5ms\n",
            "image 78/80 /content/yolov5/21322100-1/test/images/zoe-gayah-jonker-uhnbTZC7N9k-unsplash_jpg.rf.ee89d0ecfa10903396497315414cff13.jpg: 416x416 1 Cat, 8.1ms\n",
            "image 79/80 /content/yolov5/21322100-1/test/images/zoe-schaeffer-gHAAa9U4a0k-unsplash_jpg.rf.f9acada6a41302e647e07683fb798b49.jpg: 416x416 1 Chicken, 8.4ms\n",
            "image 80/80 /content/yolov5/21322100-1/test/images/zoe-schaeffer-vpDQgn0npaU-unsplash_jpg.rf.56de7ab26c82d5ecda402fcfad75cb83.jpg: 416x416 1 Person, 8.6ms\n",
            "Speed: 0.4ms pre-process, 9.3ms inference, 1.0ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Train 2\n",
        "changing the epochs to number 50 and reducing the batch size to 10"
      ],
      "metadata": {
        "id": "UA8Dow-U63bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 10 --epochs 50 --data /content/yolov5/21322100-1/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz5Sqi4i7KYk",
        "outputId": "c2e6d8c6-98b2-4524-fde8-da54be25641b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/21322100-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=10, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/21322100-1/train/labels.cache... 400 images, 0 backgrounds, 0 corrupt: 100% 400/400 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 400/400 [00:02<00:00, 175.84it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/21322100-1/test/labels.cache... 480 images, 0 backgrounds, 0 corrupt: 100% 480/480 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB ram): 100% 480/480 [00:04<00:00, 102.60it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49         1G     0.1007    0.02509    0.06135         35        416: 100% 40/40 [00:08<00:00,  4.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:04<00:00,  5.81it/s]\n",
            "                   all        480        803    0.00531      0.809     0.0589     0.0192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49      1.23G    0.07296    0.02787    0.05407         31        416: 100% 40/40 [00:05<00:00,  7.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.29it/s]\n",
            "                   all        480        803      0.243      0.417      0.216     0.0786\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49      1.23G    0.06686    0.02321    0.05056         39        416: 100% 40/40 [00:05<00:00,  7.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.62it/s]\n",
            "                   all        480        803      0.199      0.265      0.212     0.0921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49      1.23G    0.06158    0.02402    0.04485         25        416: 100% 40/40 [00:05<00:00,  7.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.64it/s]\n",
            "                   all        480        803      0.281      0.422      0.266      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49      1.23G    0.05634    0.02085    0.04361         19        416: 100% 40/40 [00:05<00:00,  7.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.90it/s]\n",
            "                   all        480        803      0.297      0.404      0.265     0.0937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49      1.23G     0.0551    0.02024    0.03795         26        416: 100% 40/40 [00:05<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.96it/s]\n",
            "                   all        480        803      0.459      0.457      0.416      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49      1.23G    0.05198     0.0202    0.03854         34        416: 100% 40/40 [00:05<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.06it/s]\n",
            "                   all        480        803      0.542      0.526      0.535      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49      1.23G    0.04978    0.01974    0.03436         23        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.82it/s]\n",
            "                   all        480        803      0.561      0.526      0.518      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49      1.23G    0.04757     0.0199    0.03287         28        416: 100% 40/40 [00:05<00:00,  7.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.87it/s]\n",
            "                   all        480        803      0.558      0.505       0.58      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49      1.23G     0.0458    0.01864    0.03237         33        416: 100% 40/40 [00:05<00:00,  7.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.91it/s]\n",
            "                   all        480        803      0.634      0.578      0.627       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49      1.23G    0.04557    0.01935    0.03053         35        416: 100% 40/40 [00:05<00:00,  7.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.09it/s]\n",
            "                   all        480        803      0.664      0.623      0.664      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49      1.23G    0.04155     0.0179    0.03193         32        416: 100% 40/40 [00:05<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.98it/s]\n",
            "                   all        480        803        0.6      0.646      0.638      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49      1.23G    0.04348    0.01924    0.02868         24        416: 100% 40/40 [00:05<00:00,  7.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.90it/s]\n",
            "                   all        480        803      0.629      0.684      0.708      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49      1.23G    0.04367    0.01968    0.02741         28        416: 100% 40/40 [00:05<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.96it/s]\n",
            "                   all        480        803       0.78      0.602      0.708      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49      1.23G    0.04222    0.01924    0.02699         34        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.91it/s]\n",
            "                   all        480        803      0.693      0.674      0.738      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49      1.23G    0.04109    0.01847    0.02754         33        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.09it/s]\n",
            "                   all        480        803       0.63      0.649      0.663      0.373\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49      1.23G    0.04057    0.01848    0.02382         36        416: 100% 40/40 [00:05<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.01it/s]\n",
            "                   all        480        803      0.643      0.704      0.707      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49      1.23G    0.03994    0.01781    0.02604         38        416: 100% 40/40 [00:05<00:00,  7.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.94it/s]\n",
            "                   all        480        803      0.659      0.679      0.703       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49      1.23G    0.03859    0.01744     0.0255         24        416: 100% 40/40 [00:05<00:00,  7.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.04it/s]\n",
            "                   all        480        803      0.693       0.69      0.738      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49      1.23G    0.03914    0.01626    0.02294         31        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.08it/s]\n",
            "                   all        480        803      0.757      0.663      0.739      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49      1.23G    0.03833    0.01847    0.02453         27        416: 100% 40/40 [00:05<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:04<00:00,  5.37it/s]\n",
            "                   all        480        803       0.77      0.706      0.752      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49      1.23G    0.03757    0.01755    0.02362         32        416: 100% 40/40 [00:05<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.81it/s]\n",
            "                   all        480        803      0.751      0.738      0.782      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49      1.34G    0.03793    0.01827    0.02091         28        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.97it/s]\n",
            "                   all        480        803      0.769       0.66      0.729      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49      1.34G    0.03957    0.01757    0.01985         43        416: 100% 40/40 [00:05<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.03it/s]\n",
            "                   all        480        803      0.787      0.704      0.779      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49      1.34G    0.03748    0.01774    0.02173         25        416: 100% 40/40 [00:05<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.98it/s]\n",
            "                   all        480        803      0.824      0.765      0.832      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49      1.34G    0.03653    0.01887    0.01858         34        416: 100% 40/40 [00:05<00:00,  7.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.01it/s]\n",
            "                   all        480        803      0.835      0.745      0.809       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49      1.34G    0.03456    0.01801    0.01818         33        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.95it/s]\n",
            "                   all        480        803      0.849      0.756      0.834      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49      1.34G    0.03461    0.01642    0.01852         29        416: 100% 40/40 [00:05<00:00,  7.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.81it/s]\n",
            "                   all        480        803      0.818       0.77      0.831      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49      1.34G    0.03482    0.01734    0.01653         40        416: 100% 40/40 [00:05<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.76it/s]\n",
            "                   all        480        803      0.821      0.757      0.838      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49      1.34G    0.03463    0.01692    0.01781         31        416: 100% 40/40 [00:05<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.77it/s]\n",
            "                   all        480        803      0.848      0.791      0.842      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49      1.34G    0.03358    0.01644    0.01617         20        416: 100% 40/40 [00:05<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.83it/s]\n",
            "                   all        480        803      0.869      0.763      0.843      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49      1.34G    0.03184    0.01671    0.01774         32        416: 100% 40/40 [00:05<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.79it/s]\n",
            "                   all        480        803      0.864      0.805      0.863      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49      1.34G    0.03223    0.01596    0.01494         24        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.97it/s]\n",
            "                   all        480        803      0.905      0.797      0.871      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49      1.34G    0.03297     0.0166     0.0147         24        416: 100% 40/40 [00:05<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.16it/s]\n",
            "                   all        480        803      0.878      0.798      0.862      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49      1.34G     0.0335    0.01614    0.01458         24        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.91it/s]\n",
            "                   all        480        803      0.884      0.809      0.867      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49      1.34G    0.03089    0.01711    0.01472         35        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.12it/s]\n",
            "                   all        480        803      0.867      0.802      0.851      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49      1.34G    0.03208    0.01722    0.01548         29        416: 100% 40/40 [00:05<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.00it/s]\n",
            "                   all        480        803      0.912      0.799      0.874      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49      1.34G    0.03081    0.01672    0.01426         30        416: 100% 40/40 [00:05<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.97it/s]\n",
            "                   all        480        803      0.906      0.823      0.884      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49      1.34G    0.03102    0.01678    0.01363         24        416: 100% 40/40 [00:05<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.06it/s]\n",
            "                   all        480        803      0.903      0.819      0.879      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49      1.34G    0.03068     0.0159    0.01344         28        416: 100% 40/40 [00:05<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803      0.907      0.835      0.883       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49      1.34G    0.02917    0.01624    0.01279         23        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.09it/s]\n",
            "                   all        480        803      0.911      0.823      0.883      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49      1.34G    0.02935    0.01521    0.01313         35        416: 100% 40/40 [00:05<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.98it/s]\n",
            "                   all        480        803       0.91      0.807      0.873      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49      1.34G    0.02855    0.01483    0.01203         23        416: 100% 40/40 [00:05<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.04it/s]\n",
            "                   all        480        803      0.919      0.834      0.893      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49      1.34G    0.02735    0.01446    0.01235         25        416: 100% 40/40 [00:05<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:04<00:00,  5.04it/s]\n",
            "                   all        480        803      0.929       0.84      0.896      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49      1.34G    0.02707    0.01513    0.01377         22        416: 100% 40/40 [00:05<00:00,  7.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.88it/s]\n",
            "                   all        480        803      0.921      0.848        0.9      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49      1.34G    0.02953    0.01541    0.01075         30        416: 100% 40/40 [00:05<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.10it/s]\n",
            "                   all        480        803      0.912      0.846      0.897      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49      1.34G     0.0282    0.01574    0.01125         35        416: 100% 40/40 [00:05<00:00,  7.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.87it/s]\n",
            "                   all        480        803      0.925      0.849      0.905      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49      1.34G    0.02756    0.01534    0.01129         39        416: 100% 40/40 [00:05<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.87it/s]\n",
            "                   all        480        803      0.937       0.85      0.905      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49      1.34G    0.02615    0.01482    0.01067         24        416: 100% 40/40 [00:05<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.71it/s]\n",
            "                   all        480        803       0.93       0.85      0.905      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49      1.34G    0.02757    0.01497   0.009295         25        416: 100% 40/40 [00:05<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.90it/s]\n",
            "                   all        480        803       0.92      0.852      0.905      0.683\n",
            "\n",
            "50 epochs completed in 0.134 hours.\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp3/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.48it/s]\n",
            "                   all        480        803      0.937       0.85      0.906      0.683\n",
            "                  Bear        480         59      0.935      0.881       0.95      0.773\n",
            "                   Cat        480         92      0.963      0.846      0.942      0.659\n",
            "                Cattle        480        135      0.955      0.926      0.962      0.679\n",
            "               Chicken        480         89      0.966       0.73      0.786      0.621\n",
            "                   Dog        480        106      0.858      0.896      0.921      0.672\n",
            "              Elephant        480         86          1      0.892       0.96      0.803\n",
            "                Person        480        156      0.881      0.744      0.795      0.532\n",
            "                   Pig        480         80      0.936      0.887       0.93      0.723\n",
            "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Test 2\n",
        "Test the model again using the last train"
      ],
      "metadata": {
        "id": "y8s5DZ90DAE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model again using same test images with the runs/train/exp3 path\n",
        "!python detect.py --weights runs/train/exp3/weights/best.pt --img 416 --conf 0.1 --source /content/yolov5/21322100-1/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyuMFY2-9T-S",
        "outputId": "939f55c2-0e2d-4fd9-bd26-b82c7de46a5f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp3/weights/best.pt'], source=/content/yolov5/21322100-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/80 /content/yolov5/21322100-1/test/images/20221023_140514_jpg.rf.8b5bf371e23b3fe491ce05f48b662d27.jpg: 416x416 3 Persons, 8.8ms\n",
            "image 2/80 /content/yolov5/21322100-1/test/images/alexander-krivitskiy-tSX6E9UextA-unsplash_jpg.rf.cf87c8c0f5d7066f99d4f3a0d0bb48ae.jpg: 416x416 1 Person, 8.4ms\n",
            "image 3/80 /content/yolov5/21322100-1/test/images/anmol-kerketta-QrOaXkjqmA-unsplash_jpg.rf.0351c81b96b9db1281de92d9e05d225a.jpg: 416x416 2 Cattles, 2 Persons, 8.4ms\n",
            "image 4/80 /content/yolov5/21322100-1/test/images/becca-_r6w0R6SueQ-unsplash_jpg.rf.3678b452df112264dc0b37eae89f4996.jpg: 416x416 1 Bear, 8.3ms\n",
            "image 5/80 /content/yolov5/21322100-1/test/images/cat_100_jpg.rf.37a5d055ee290eca8d56160bcc3e6f04.jpg: 416x416 1 Cat, 8.5ms\n",
            "image 6/80 /content/yolov5/21322100-1/test/images/charlesdeluvio-Mv9hjnEUHR4-unsplash_jpg.rf.6f999711dc619c68a2395ade979fb412.jpg: 416x416 1 Chicken, 8.2ms\n",
            "image 7/80 /content/yolov5/21322100-1/test/images/danie-franco-A6O7pgc7vHg-unsplash_jpg.rf.94628720c4e4ab5bcca134c673b56a41.jpg: 416x416 1 Person, 8.1ms\n",
            "image 8/80 /content/yolov5/21322100-1/test/images/debbie-molle-6DSID8Ey9-U-unsplash_jpg.rf.b56dfb25e6eae4eb2e93d0e4a18aa719.jpg: 416x416 2 Bears, 1 Pig, 9.1ms\n",
            "image 9/80 /content/yolov5/21322100-1/test/images/deon-de-villiers-7HRHhcueqZ8-unsplash_jpg.rf.f5d19c70ab91d2d458253563f9132c71.jpg: 416x416 4 Elephants, 3 Pigs, 9.1ms\n",
            "image 10/80 /content/yolov5/21322100-1/test/images/dog_54_jpg.rf.1b3a36fc8f1cef43cbfb1ebcfae0b392.jpg: 416x416 2 Dogs, 4 Persons, 8.3ms\n",
            "image 11/80 /content/yolov5/21322100-1/test/images/dog_78_jpg.rf.ad78df5fa2fd9e1cbc3c25b3907e0a9b.jpg: 416x416 2 Dogs, 8.1ms\n",
            "image 12/80 /content/yolov5/21322100-1/test/images/dusan-veverkolog-ETsFvMEBKTw-unsplash_jpg.rf.af46abd924bba409482c8f8a970a657b.jpg: 416x416 1 Bear, 8.5ms\n",
            "image 13/80 /content/yolov5/21322100-1/test/images/eliott-reyna-jCEpN62oWL4-unsplash_jpg.rf.85cf78c4e4b34303947ea3f5a55039b5.jpg: 416x416 7 Persons, 8.7ms\n",
            "image 14/80 /content/yolov5/21322100-1/test/images/ellicia-IgdVdJCmzf4-unsplash_jpg.rf.f8b8e140b5b4362d1c6afd8af8ca885c.jpg: 416x416 1 Bear, 1 Pig, 8.2ms\n",
            "image 15/80 /content/yolov5/21322100-1/test/images/flouffy-7hEXd9kYPCY-unsplash_jpg.rf.a8496866dd6f4e7c9494453c445e33f0.jpg: 416x416 1 Dog, 8.8ms\n",
            "image 16/80 /content/yolov5/21322100-1/test/images/gemma-chua-tran-Ftvf4VbVbDE-unsplash_jpg.rf.63e45ca610945c605433fc3c62f05d39.jpg: 416x416 1 Person, 8.2ms\n",
            "image 17/80 /content/yolov5/21322100-1/test/images/hadis-safari-A7rkoSFjrG0-unsplash_jpg.rf.038cd34896f4536d51ba7153fd30a1ea.jpg: 416x416 1 Person, 9.0ms\n",
            "image 18/80 /content/yolov5/21322100-1/test/images/hans-jurgen-mager-Opd59VdnPn0-unsplash_jpg.rf.ed5bde8aeb9e894e8cad33fc1a49fc39.jpg: 416x416 1 Dog, 8.5ms\n",
            "image 19/80 /content/yolov5/21322100-1/test/images/hyunwon-jang-LYK3ksSQyeo-unsplash_jpg.rf.a8919fed6bf75b009fc84f0547611195.jpg: 416x416 1 Cattle, 8.1ms\n",
            "image 20/80 /content/yolov5/21322100-1/test/images/ilse-orsel-vmFEBIEz0hQ-unsplash_jpg.rf.9a4736f9b1cbb244633fc01cdbaefa97.jpg: 416x416 3 Cats, 8.2ms\n",
            "image 21/80 /content/yolov5/21322100-1/test/images/jean-wimmerlin-Ypv-kNjcnDA-unsplash_jpg.rf.060e85699e4fd10c87b7f10d049fe6e0.jpg: 416x416 2 Elephants, 8.8ms\n",
            "image 22/80 /content/yolov5/21322100-1/test/images/jessica-weiller-kZ8dyUT0h30-unsplash_jpg.rf.65afe9638114a15a988fdf9fba189ebe.jpg: 416x416 1 Bear, 9.9ms\n",
            "image 23/80 /content/yolov5/21322100-1/test/images/john-matychuk-jDRTl-w5jtY-unsplash_jpg.rf.fbdb07d243626a7899f43d071075ddda.jpg: 416x416 1 Elephant, 9.5ms\n",
            "image 24/80 /content/yolov5/21322100-1/test/images/jonny-gios-VYQRj0e54u8-unsplash_jpg.rf.19004b6dc593345d2a6481bffc2502c1.jpg: 416x416 1 Chicken, 9.8ms\n",
            "image 25/80 /content/yolov5/21322100-1/test/images/jopeel-quimpo-FBkgT8Y4mLw-unsplash_jpg.rf.8701dc5143cec5bf1fe8ef960b3c22c7.jpg: 416x416 1 Chicken, 10.2ms\n",
            "image 26/80 /content/yolov5/21322100-1/test/images/julien-mussard-OApeDBma_zY-unsplash_jpg.rf.34636742e0e2f7658b45716fa5a55c0d.jpg: 416x416 1 Bear, 9.3ms\n",
            "image 27/80 /content/yolov5/21322100-1/test/images/karsten-winegeart-BJaqPaH6AGQ-unsplash_jpg.rf.ea5123803ee66bcfb6d5af91b4f3ab09.jpg: 416x416 1 Dog, 1 Person, 10.2ms\n",
            "image 28/80 /content/yolov5/21322100-1/test/images/karsten-winegeart-Qb7D1xw28Co-unsplash_jpg.rf.34ca61d415ab0d4f6c01362740a16f24.jpg: 416x416 1 Dog, 9.5ms\n",
            "image 29/80 /content/yolov5/21322100-1/test/images/kelly-e1u0YdAkh9k-unsplash_jpg.rf.d84194b06560ea492b4582fff3d1c6c8.jpg: 416x416 2 Dogs, 1 Person, 12.7ms\n",
            "image 30/80 /content/yolov5/21322100-1/test/images/kote-puerto-so5nsYDOdxw-unsplash_jpg.rf.7d4c38c695002b8bea91a1f21c49c7cb.jpg: 416x416 2 Cats, 9.4ms\n",
            "image 31/80 /content/yolov5/21322100-1/test/images/kyle-mackie-rIo3D0hnVAg-unsplash_jpg.rf.88df4905f1f61c06316768032fb4b96d.jpg: 416x416 9 Cattles, 8.6ms\n",
            "image 32/80 /content/yolov5/21322100-1/test/images/larry-costales-Ahf1ZmcKzgE-unsplash_jpg.rf.f88335097ce2201a2f6e9565a8af896e.jpg: 416x416 1 Cattle, 9.2ms\n",
            "image 33/80 /content/yolov5/21322100-1/test/images/lucrezia-carnelos-0liYTl4dJxk-unsplash_jpg.rf.cf22ce3ee73643410b07c3635759d3fb.jpg: 416x416 1 Dog, 8.8ms\n",
            "image 34/80 /content/yolov5/21322100-1/test/images/marek-piwnicki-PUVVsYJPh78-unsplash_jpg.rf.95ffaf9cb2945205312a35af01625b35.jpg: 416x416 3 Pigs, 8.1ms\n",
            "image 35/80 /content/yolov5/21322100-1/test/images/mathilda-khoo-vLR0YP_otCo-unsplash_jpg.rf.7bec4a1e035e73be9aad36d2e88274ef.jpg: 416x416 1 Person, 8.4ms\n",
            "image 36/80 /content/yolov5/21322100-1/test/images/matt-quinn-Q6-jv031muY-unsplash_jpg.rf.179e1cd8437e5355a5b5e8fa26e5030a.jpg: 416x416 18 Persons, 8.6ms\n",
            "image 37/80 /content/yolov5/21322100-1/test/images/matthew-spiteri-WfZ4WCuNtlg-unsplash_jpg.rf.00207cbec5f3067895bcb1b49d94e5f6.jpg: 416x416 4 Elephants, 8.7ms\n",
            "image 38/80 /content/yolov5/21322100-1/test/images/max-saeling-s3fOyTAOUUU-unsplash_jpg.rf.d06382cd7eb136b2b53bf16a3e60674c.jpg: 416x416 1 Cat, 5 Cattles, 2 Dogs, 1 Pig, 8.5ms\n",
            "image 39/80 /content/yolov5/21322100-1/test/images/megan-soule-xbVIg4Sjkc4-unsplash_jpg.rf.7540f4b60d6adf71e6642197813b3eb1.jpg: 416x416 1 Elephant, 1 Person, 8.5ms\n",
            "image 40/80 /content/yolov5/21322100-1/test/images/milk-tea-h7Dw2hF4e0A-unsplash_jpg.rf.55c72d4095796f4440d1bacd0d3acdfc.jpg: 416x416 1 Cat, 8.3ms\n",
            "image 41/80 /content/yolov5/21322100-1/test/images/mohammed-alzubidi-TZVYwkLDX1E-unsplash_jpg.rf.274795cac21b991d65cf1aeec8cdf140.jpg: 416x416 2 Cattles, 10.8ms\n",
            "image 42/80 /content/yolov5/21322100-1/test/images/nadi-whatisdelirium-fZ8uf_L52wg-unsplash_jpg.rf.048d91d1121171ef2a78fa7b4349315c.jpg: 416x416 1 Dog, 1 Person, 9.0ms\n",
            "image 43/80 /content/yolov5/21322100-1/test/images/nebojsa-ilic-w7QGY1ZNFds-unsplash_jpg.rf.229e1cd848bf6810a265b13bba366b41.jpg: 416x416 1 Cat, 1 Elephant, 1 Pig, 8.2ms\n",
            "image 44/80 /content/yolov5/21322100-1/test/images/nicholas-green-nPz8akkUmDI-unsplash_jpg.rf.2b4141706259f43bbf4accdbbdc3eba2.jpg: 416x416 8 Persons, 8.6ms\n",
            "image 45/80 /content/yolov5/21322100-1/test/images/omar-lopez-T6zu4jFhVwg-unsplash_jpg.rf.abc4f162f20d153a3e748a820de7071c.jpg: 416x416 1 Cat, 11 Persons, 8.6ms\n",
            "image 46/80 /content/yolov5/21322100-1/test/images/patrick-pahlke-21iYB5pAtGg-unsplash_jpg.rf.f196ba531f0d1ce2ce1772f622b549ff.jpg: 416x416 2 Cats, 1 Chicken, 9.0ms\n",
            "image 47/80 /content/yolov5/21322100-1/test/images/paul-szewczyk-fHLqRr2b7CU-unsplash_jpg.rf.499fa608f23bf63bc4607f3389fc19e9.jpg: 416x416 2 Cattles, 2 Persons, 8.9ms\n",
            "image 48/80 /content/yolov5/21322100-1/test/images/qijin-xu-vQUXUHjyy8A-unsplash_jpg.rf.d02d785f40f429792840b65013c0c3f1.jpg: 416x416 1 Dog, 1 Person, 8.3ms\n",
            "image 49/80 /content/yolov5/21322100-1/test/images/raoul-droog-yMSecCHsIBc-unsplash_jpg.rf.1e1eab32da5bb356bed168df04ebc50a.jpg: 416x416 1 Cat, 1 Person, 8.8ms\n",
            "image 50/80 /content/yolov5/21322100-1/test/images/remi-remino-E9kVmtiqqGE-unsplash_jpg.rf.9957264ed9e9f54b91fa812531c34a43.jpg: 416x416 1 Cat, 9.4ms\n",
            "image 51/80 /content/yolov5/21322100-1/test/images/richard-jacobs-8oenpCXktqQ-unsplash_jpg.rf.99981c1a76d2a00973e87c335f8f1d94.jpg: 416x416 2 Elephants, 8.4ms\n",
            "image 52/80 /content/yolov5/21322100-1/test/images/robert-bottman-IZiAUsTFZm4-unsplash_jpg.rf.4fbe21dc3012eeac9f5ef50595d78585.jpg: 416x416 1 Chicken, 1 Person, 14.5ms\n",
            "image 53/80 /content/yolov5/21322100-1/test/images/roberto-nickson-udjuFffdtWY-unsplash_jpg.rf.8aa467ddf1f21d0899c5ef324be28d5d.jpg: 416x416 1 Bear, 1 Person, 1 Pig, 9.0ms\n",
            "image 54/80 /content/yolov5/21322100-1/test/images/sarah-halliday-IuaPUiQotdU-unsplash_jpg.rf.2f2942d90f2e537a3d9408bb37043caf.jpg: 416x416 1 Chicken, 8.3ms\n",
            "image 55/80 /content/yolov5/21322100-1/test/images/senjuti-kundu-JfolIjRnveY-unsplash_jpg.rf.42129051d455c3091b13c0b5b2ffcf28.jpg: 416x416 1 Chicken, 8.6ms\n",
            "image 56/80 /content/yolov5/21322100-1/test/images/serge-le-strat-g3QTR9n7hsg-unsplash_jpg.rf.51ade13804e100d75ad13e6d470d5f09.jpg: 416x416 5 Cattles, 8.6ms\n",
            "image 57/80 /content/yolov5/21322100-1/test/images/sergio-ortega-7ce10LAA9HE-unsplash_jpg.rf.e6a3d93e5bf79e685315d060079c426d.jpg: 416x416 4 Elephants, 8.8ms\n",
            "image 58/80 /content/yolov5/21322100-1/test/images/sherard-campbell-Mzy3CT69Tns-unsplash_jpg.rf.6241ed00c834de63e543a32c63efe3c4.jpg: 416x416 1 Dog, 8.5ms\n",
            "image 59/80 /content/yolov5/21322100-1/test/images/sherard-campbell-OmF9_5i2muo-unsplash_jpg.rf.234707d4c701a6de760e15a4a002714d.jpg: 416x416 1 Pig, 8.2ms\n",
            "image 60/80 /content/yolov5/21322100-1/test/images/sikes-photos-FBVWVwbR5-w-unsplash_jpg.rf.706e5d84785a6967e2d96def4f6da058.jpg: 416x416 6 Cattles, 8.2ms\n",
            "image 61/80 /content/yolov5/21322100-1/test/images/sinval-carvalho-jTnSTGeXvNs-unsplash_jpg.rf.2a61b4c6784e6af5278e5cfbb04ce5f6.jpg: 416x416 1 Bear, 8.2ms\n",
            "image 62/80 /content/yolov5/21322100-1/test/images/sippakorn-yamkasikorn-wWIK8hnESnY-unsplash_jpg.rf.3a7ae2b5d94df424ec40dd933b437943.jpg: 416x416 1 Chicken, 8.7ms\n",
            "image 63/80 /content/yolov5/21322100-1/test/images/steven-boesky-6GH00hMbjPI-unsplash_jpg.rf.9ce367e4f7f403c3226964d908e2fa9a.jpg: 416x416 1 Chicken, 9.0ms\n",
            "image 64/80 /content/yolov5/21322100-1/test/images/sutirta-budiman-Xm_d76KavOk-unsplash_jpg.rf.d59ccf57bce0a190ed7c42f697dea57c.jpg: 416x416 1 Elephant, 14.8ms\n",
            "image 65/80 /content/yolov5/21322100-1/test/images/taylor-kopel-WX4i1Jq_o0Y-unsplash_jpg.rf.d80441d39ead18e2bd6151cd64251c08.jpg: 416x416 1 Chicken, 1 Dog, 1 Pig, 10.5ms\n",
            "image 66/80 /content/yolov5/21322100-1/test/images/thomas-iversen-4W8FgDVyUME-unsplash_jpg.rf.ae2543055732239de0f56a6f29bc2dd3.jpg: 416x416 3 Chickens, 10.1ms\n",
            "image 67/80 /content/yolov5/21322100-1/test/images/thomas-lipke-KCyLa5xkoic-unsplash_jpg.rf.b0c7adcaf92416bff963d33047fb755e.jpg: 416x416 1 Bear, 10.1ms\n",
            "image 68/80 /content/yolov5/21322100-1/test/images/thomas-m-evans-mg2ACzid4fY-unsplash_jpg.rf.4403978d83ed0121c1726265c2ded413.jpg: 416x416 1 Elephant, 1 Pig, 9.6ms\n",
            "image 69/80 /content/yolov5/21322100-1/test/images/victor-grabarczyk-2pbnDRhXc6Q-unsplash_jpg.rf.d0d713f089fc2d68e8bb6ab824fc2ad2.jpg: 416x416 1 Dog, 9.7ms\n",
            "image 70/80 /content/yolov5/21322100-1/test/images/vito-natale-avMIDf1WPCg-unsplash_jpg.rf.7a7c9682ca2533f20e353c4168c72f95.jpg: 416x416 1 Pig, 9.6ms\n",
            "image 71/80 /content/yolov5/21322100-1/test/images/wade-austin-ellis-FtuJIuBbUhI-unsplash_jpg.rf.6254154ad3a51815990360325eb1e5fc.jpg: 416x416 1 Dog, 2 Persons, 9.6ms\n",
            "image 72/80 /content/yolov5/21322100-1/test/images/will-h-mcmahan-jM73872dy4Y-unsplash_jpg.rf.4ae7091b3f5206dbf3c6a69662b4a7f4.jpg: 416x416 2 Cattles, 2 Chickens, 9.5ms\n",
            "image 73/80 /content/yolov5/21322100-1/test/images/will-shirley-sbyEMIcFx34-unsplash_jpg.rf.7cbb09cc12737472ff76615841296f12.jpg: 416x416 1 Elephant, 9.0ms\n",
            "image 74/80 /content/yolov5/21322100-1/test/images/wolfgang-hasselmann-2zSkt52ELsk-unsplash_jpg.rf.30a3eb81f174566a2a3483629dc90364.jpg: 416x416 3 Elephants, 1 Person, 9.5ms\n",
            "image 75/80 /content/yolov5/21322100-1/test/images/wolfgang-hasselmann-W99CE3hOKf4-unsplash_jpg.rf.303c42e0e8a3314f3ed6c3f8d5ef0c0e.jpg: 416x416 1 Cattle, 8.8ms\n",
            "image 76/80 /content/yolov5/21322100-1/test/images/zdenek-machacek-PK94wCeXdjA-unsplash_jpg.rf.8535e87495c0ed8635bc42acec03a1af.jpg: 416x416 1 Bear, 8.9ms\n",
            "image 77/80 /content/yolov5/21322100-1/test/images/zdenek-machacek-hztya2tQqB8-unsplash_jpg.rf.a15db390eae3413edbd1a95d7483611e.jpg: 416x416 1 Bear, 2 Cats, 8.7ms\n",
            "image 78/80 /content/yolov5/21322100-1/test/images/zoe-gayah-jonker-uhnbTZC7N9k-unsplash_jpg.rf.ee89d0ecfa10903396497315414cff13.jpg: 416x416 1 Cat, 9.1ms\n",
            "image 79/80 /content/yolov5/21322100-1/test/images/zoe-schaeffer-gHAAa9U4a0k-unsplash_jpg.rf.f9acada6a41302e647e07683fb798b49.jpg: 416x416 1 Chicken, 1 Pig, 8.5ms\n",
            "image 80/80 /content/yolov5/21322100-1/test/images/zoe-schaeffer-vpDQgn0npaU-unsplash_jpg.rf.56de7ab26c82d5ecda402fcfad75cb83.jpg: 416x416 1 Elephant, 1 Person, 8.6ms\n",
            "Speed: 0.4ms pre-process, 9.1ms inference, 1.0ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Train 3\n",
        "Increasing the epoch size to 70 and maintaing the batch size to be 10"
      ],
      "metadata": {
        "id": "U0iToyUkC1Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training path \n",
        "!python train.py --img 416 --batch 10 --epochs 70 --data /content/yolov5/21322100-1/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSMWNnu59io6",
        "outputId": "c4b2a8a4-d21e-406e-9ed8-912458e6b391"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/21322100-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=70, batch_size=10, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/21322100-1/train/labels.cache... 400 images, 0 backgrounds, 0 corrupt: 100% 400/400 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 400/400 [00:02<00:00, 174.21it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/21322100-1/test/labels.cache... 480 images, 0 backgrounds, 0 corrupt: 100% 480/480 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB ram): 100% 480/480 [00:04<00:00, 105.64it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.11 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp4/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
            "Starting training for 70 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/69         1G     0.1007    0.02509    0.06135         35        416: 100% 40/40 [00:08<00:00,  4.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:04<00:00,  5.78it/s]\n",
            "                   all        480        803    0.00531      0.809     0.0589     0.0192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/69      1.23G    0.07291    0.02786      0.054         31        416: 100% 40/40 [00:05<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.36it/s]\n",
            "                   all        480        803      0.235      0.409      0.232     0.0996\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/69      1.23G    0.06564    0.02328    0.05001         39        416: 100% 40/40 [00:05<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.69it/s]\n",
            "                   all        480        803      0.244       0.31      0.232      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/69      1.23G    0.05947    0.02421    0.04394         25        416: 100% 40/40 [00:05<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.61it/s]\n",
            "                   all        480        803      0.285      0.348      0.246      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/69      1.23G    0.05744    0.02075    0.04286         19        416: 100% 40/40 [00:05<00:00,  7.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.88it/s]\n",
            "                   all        480        803      0.297       0.42      0.321      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/69      1.23G    0.05683     0.0199    0.03737         26        416: 100% 40/40 [00:05<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.01it/s]\n",
            "                   all        480        803      0.437      0.491      0.465      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/69      1.23G    0.05182    0.02027    0.03929         34        416: 100% 40/40 [00:06<00:00,  5.95it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.00it/s]\n",
            "                   all        480        803      0.349      0.494      0.412      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/69      1.23G     0.0488    0.02012    0.03482         23        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.97it/s]\n",
            "                   all        480        803      0.454        0.5      0.474      0.227\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/69      1.23G     0.0468    0.02057    0.03443         28        416: 100% 40/40 [00:05<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.08it/s]\n",
            "                   all        480        803      0.501      0.567      0.525      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/69      1.23G    0.04563    0.01896      0.033         33        416: 100% 40/40 [00:05<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803      0.589      0.472      0.491      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/69      1.23G    0.04582    0.01976    0.03256         35        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.93it/s]\n",
            "                   all        480        803      0.574        0.6      0.615      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/69      1.23G    0.04345     0.0186    0.03353         32        416: 100% 40/40 [00:05<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.14it/s]\n",
            "                   all        480        803      0.602      0.563      0.579      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/69      1.23G    0.04396    0.01997    0.02991         24        416: 100% 40/40 [00:05<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.19it/s]\n",
            "                   all        480        803      0.605      0.583       0.61      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/69      1.23G    0.04584    0.02052    0.02859         28        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.82it/s]\n",
            "                   all        480        803      0.623      0.609      0.614      0.333\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/69      1.23G    0.04348    0.01985    0.02937         34        416: 100% 40/40 [00:05<00:00,  7.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.87it/s]\n",
            "                   all        480        803      0.614      0.526       0.55       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/69      1.23G    0.04338    0.01935    0.03048         33        416: 100% 40/40 [00:05<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.16it/s]\n",
            "                   all        480        803      0.626      0.657      0.681      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/69      1.23G    0.04273    0.01938    0.02553         36        416: 100% 40/40 [00:05<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.99it/s]\n",
            "                   all        480        803      0.589      0.593      0.603       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/69      1.23G    0.04228    0.01899    0.02939         38        416: 100% 40/40 [00:05<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803       0.67      0.604       0.67      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/69      1.23G    0.04113    0.01836    0.02786         24        416: 100% 40/40 [00:05<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.11it/s]\n",
            "                   all        480        803       0.71      0.639      0.692      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/69      1.23G    0.04045    0.01689    0.02448         31        416: 100% 40/40 [00:05<00:00,  7.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.00it/s]\n",
            "                   all        480        803      0.643      0.597      0.639      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/69      1.23G    0.03961    0.01915    0.02463         27        416: 100% 40/40 [00:05<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.05it/s]\n",
            "                   all        480        803      0.663      0.631      0.629      0.354\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/69      1.23G    0.04037    0.01804    0.02413         32        416: 100% 40/40 [00:05<00:00,  7.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.03it/s]\n",
            "                   all        480        803      0.745      0.684      0.731       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/69      1.34G    0.04027    0.01862     0.0209         28        416: 100% 40/40 [00:05<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.02it/s]\n",
            "                   all        480        803      0.764       0.67       0.75      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/69      1.34G    0.04172    0.01801    0.01996         43        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.11it/s]\n",
            "                   all        480        803      0.721       0.66      0.705      0.441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/69      1.34G    0.04013    0.01825    0.02205         25        416: 100% 40/40 [00:05<00:00,  7.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.11it/s]\n",
            "                   all        480        803      0.746       0.71      0.747      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/69      1.34G    0.03831    0.01965    0.02115         34        416: 100% 40/40 [00:05<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.00it/s]\n",
            "                   all        480        803      0.711      0.701      0.714      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/69      1.34G    0.03722    0.01885    0.02037         33        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.84it/s]\n",
            "                   all        480        803      0.777      0.742      0.795      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/69      1.34G    0.03766    0.01708    0.02039         29        416: 100% 40/40 [00:05<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.14it/s]\n",
            "                   all        480        803      0.823      0.715      0.781      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/69      1.34G    0.03763    0.01803    0.01761         40        416: 100% 40/40 [00:05<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.06it/s]\n",
            "                   all        480        803      0.789      0.701      0.766      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/69      1.34G    0.03735    0.01754    0.02078         31        416: 100% 40/40 [00:06<00:00,  6.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:04<00:00,  5.96it/s]\n",
            "                   all        480        803      0.837      0.738       0.82      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/69      1.34G    0.03615    0.01743    0.01853         20        416: 100% 40/40 [00:05<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.98it/s]\n",
            "                   all        480        803      0.842      0.702      0.801      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/69      1.34G    0.03404    0.01759    0.01908         32        416: 100% 40/40 [00:05<00:00,  7.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.92it/s]\n",
            "                   all        480        803      0.852      0.725      0.807      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/69      1.34G    0.03475     0.0168    0.01726         24        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.04it/s]\n",
            "                   all        480        803      0.854      0.764      0.812      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/69      1.34G    0.03636    0.01757    0.01656         24        416: 100% 40/40 [00:05<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.89it/s]\n",
            "                   all        480        803      0.857      0.778      0.829      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/69      1.34G    0.03689    0.01706    0.01586         24        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.10it/s]\n",
            "                   all        480        803      0.823      0.801      0.839       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/69      1.34G    0.03443    0.01775    0.01676         35        416: 100% 40/40 [00:05<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.02it/s]\n",
            "                   all        480        803      0.767      0.728      0.764      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/69      1.34G    0.03535    0.01797    0.01561         29        416: 100% 40/40 [00:05<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.93it/s]\n",
            "                   all        480        803      0.817      0.778      0.804      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/69      1.34G    0.03408    0.01748    0.01701         30        416: 100% 40/40 [00:05<00:00,  7.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.16it/s]\n",
            "                   all        480        803       0.87      0.786      0.854      0.573\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/69      1.34G    0.03388    0.01764     0.0147         24        416: 100% 40/40 [00:05<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803        0.9      0.777       0.86      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/69      1.34G    0.03386    0.01683     0.0154         28        416: 100% 40/40 [00:05<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.03it/s]\n",
            "                   all        480        803      0.886      0.793      0.859      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/69      1.34G    0.03218    0.01687    0.01434         23        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.11it/s]\n",
            "                   all        480        803      0.872      0.814      0.865      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/69      1.34G     0.0333    0.01614    0.01491         35        416: 100% 40/40 [00:05<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.13it/s]\n",
            "                   all        480        803      0.896      0.824      0.879      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/69      1.34G    0.03135    0.01561    0.01519         23        416: 100% 40/40 [00:05<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.95it/s]\n",
            "                   all        480        803      0.912      0.825      0.871      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/69      1.34G    0.03037     0.0151    0.01481         25        416: 100% 40/40 [00:05<00:00,  7.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.17it/s]\n",
            "                   all        480        803      0.905      0.822       0.89      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/69      1.34G    0.03067    0.01597    0.01503         22        416: 100% 40/40 [00:05<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.05it/s]\n",
            "                   all        480        803      0.886      0.841       0.89      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/69      1.34G    0.03293    0.01626    0.01239         30        416: 100% 40/40 [00:05<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803      0.905      0.827      0.882      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/69      1.34G    0.03188    0.01649    0.01236         35        416: 100% 40/40 [00:05<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.02it/s]\n",
            "                   all        480        803      0.905      0.835      0.884      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/69      1.34G    0.03121    0.01615    0.01215         39        416: 100% 40/40 [00:05<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803      0.916      0.825      0.876      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/69      1.34G    0.02967    0.01585    0.01222         24        416: 100% 40/40 [00:05<00:00,  7.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.14it/s]\n",
            "                   all        480        803      0.917      0.843      0.897      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/69      1.34G    0.03154    0.01567    0.01186         25        416: 100% 40/40 [00:05<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.88it/s]\n",
            "                   all        480        803       0.92       0.84      0.891      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/69      1.34G    0.02871    0.01503    0.01259         28        416: 100% 40/40 [00:05<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.08it/s]\n",
            "                   all        480        803      0.908      0.852      0.892      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/69      1.34G    0.03014    0.01555    0.01245         27        416: 100% 40/40 [00:05<00:00,  7.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.17it/s]\n",
            "                   all        480        803      0.919      0.848      0.893      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/69      1.34G    0.02954    0.01538    0.01132         23        416: 100% 40/40 [00:07<00:00,  5.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.60it/s]\n",
            "                   all        480        803      0.921      0.864      0.897      0.649\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/69      1.34G    0.02922    0.01577     0.0104         30        416: 100% 40/40 [00:05<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.02it/s]\n",
            "                   all        480        803      0.915       0.87      0.898      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/69      1.34G    0.02927    0.01547   0.009999         31        416: 100% 40/40 [00:05<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.13it/s]\n",
            "                   all        480        803      0.927      0.856      0.902      0.656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/69      1.34G     0.0295    0.01523    0.01249         25        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.03it/s]\n",
            "                   all        480        803      0.927      0.863      0.894      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/69      1.34G    0.02854    0.01505     0.0105         30        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.11it/s]\n",
            "                   all        480        803      0.934      0.861      0.896      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/69      1.34G    0.02807    0.01558    0.01083         33        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.09it/s]\n",
            "                   all        480        803      0.938      0.863      0.907      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/69      1.34G     0.0283    0.01533   0.008858         40        416: 100% 40/40 [00:05<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.00it/s]\n",
            "                   all        480        803       0.94      0.867      0.912      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/69      1.34G    0.02871    0.01379   0.009426         26        416: 100% 40/40 [00:05<00:00,  7.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.92it/s]\n",
            "                   all        480        803       0.93      0.874      0.913      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/69      1.34G    0.02594    0.01533   0.009725         21        416: 100% 40/40 [00:05<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.21it/s]\n",
            "                   all        480        803      0.929      0.871      0.912      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/69      1.34G    0.02763    0.01491   0.008215         36        416: 100% 40/40 [00:05<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.03it/s]\n",
            "                   all        480        803      0.932      0.865      0.906      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/69      1.34G    0.02651    0.01514   0.008885         21        416: 100% 40/40 [00:05<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.89it/s]\n",
            "                   all        480        803      0.938      0.878      0.912      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/69      1.34G    0.02568    0.01424   0.008106         28        416: 100% 40/40 [00:05<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.24it/s]\n",
            "                   all        480        803      0.937      0.881      0.916      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/69      1.34G    0.02624    0.01467    0.01033         39        416: 100% 40/40 [00:05<00:00,  7.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.07it/s]\n",
            "                   all        480        803      0.944      0.877      0.918      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/69      1.34G    0.02696    0.01504   0.007914         32        416: 100% 40/40 [00:05<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.84it/s]\n",
            "                   all        480        803      0.937      0.881      0.919      0.693\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/69      1.34G    0.02604    0.01379   0.008425         28        416: 100% 40/40 [00:05<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.96it/s]\n",
            "                   all        480        803      0.941      0.877      0.918      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/69      1.34G    0.02438      0.014   0.008303         28        416: 100% 40/40 [00:05<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.92it/s]\n",
            "                   all        480        803       0.95      0.882       0.92      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/69      1.34G    0.02489    0.01344   0.007659         34        416: 100% 40/40 [00:05<00:00,  7.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  6.88it/s]\n",
            "                   all        480        803      0.945      0.885      0.917        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/69      1.34G    0.02571    0.01422    0.00854         29        416: 100% 40/40 [00:05<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:03<00:00,  7.00it/s]\n",
            "                   all        480        803      0.941      0.879      0.916      0.703\n",
            "\n",
            "70 epochs completed in 0.186 hours.\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp4/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [00:05<00:00,  4.48it/s]\n",
            "                   all        480        803      0.941      0.879      0.916      0.703\n",
            "                  Bear        480         59      0.965       0.93      0.973        0.8\n",
            "                   Cat        480         92      0.941       0.86       0.92       0.61\n",
            "                Cattle        480        135      0.919      0.933      0.965      0.715\n",
            "               Chicken        480         89          1      0.746      0.797      0.651\n",
            "                   Dog        480        106       0.89      0.925      0.946      0.712\n",
            "              Elephant        480         86          1      0.929      0.971      0.806\n",
            "                Person        480        156      0.857      0.756      0.792       0.56\n",
            "                   Pig        480         80      0.958       0.95      0.964       0.77\n",
            "Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Test 3\n",
        "Test the train 3 using same test images "
      ],
      "metadata": {
        "id": "9eNZB8RKCttL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using \"exp4\"\n",
        "!python detect.py --weights runs/train/exp4/weights/best.pt --img 416 --conf 0.1 --source /content/yolov5/21322100-1/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyJkPEm3B3Zx",
        "outputId": "0f941b9d-a2a2-44a9-e246-bee9cce4a8a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp4/weights/best.pt'], source=/content/yolov5/21322100-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-71-gc442a2e Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/80 /content/yolov5/21322100-1/test/images/20221023_140514_jpg.rf.8b5bf371e23b3fe491ce05f48b662d27.jpg: 416x416 3 Persons, 8.9ms\n",
            "image 2/80 /content/yolov5/21322100-1/test/images/alexander-krivitskiy-tSX6E9UextA-unsplash_jpg.rf.cf87c8c0f5d7066f99d4f3a0d0bb48ae.jpg: 416x416 1 Cat, 9.8ms\n",
            "image 3/80 /content/yolov5/21322100-1/test/images/anmol-kerketta-QrOaXkjqmA-unsplash_jpg.rf.0351c81b96b9db1281de92d9e05d225a.jpg: 416x416 4 Cattles, 8.8ms\n",
            "image 4/80 /content/yolov5/21322100-1/test/images/becca-_r6w0R6SueQ-unsplash_jpg.rf.3678b452df112264dc0b37eae89f4996.jpg: 416x416 1 Bear, 9.2ms\n",
            "image 5/80 /content/yolov5/21322100-1/test/images/cat_100_jpg.rf.37a5d055ee290eca8d56160bcc3e6f04.jpg: 416x416 1 Cat, 9.9ms\n",
            "image 6/80 /content/yolov5/21322100-1/test/images/charlesdeluvio-Mv9hjnEUHR4-unsplash_jpg.rf.6f999711dc619c68a2395ade979fb412.jpg: 416x416 1 Bear, 9.7ms\n",
            "image 7/80 /content/yolov5/21322100-1/test/images/danie-franco-A6O7pgc7vHg-unsplash_jpg.rf.94628720c4e4ab5bcca134c673b56a41.jpg: 416x416 1 Person, 9.4ms\n",
            "image 8/80 /content/yolov5/21322100-1/test/images/debbie-molle-6DSID8Ey9-U-unsplash_jpg.rf.b56dfb25e6eae4eb2e93d0e4a18aa719.jpg: 416x416 2 Bears, 9.7ms\n",
            "image 9/80 /content/yolov5/21322100-1/test/images/deon-de-villiers-7HRHhcueqZ8-unsplash_jpg.rf.f5d19c70ab91d2d458253563f9132c71.jpg: 416x416 3 Cattles, 5 Elephants, 9.8ms\n",
            "image 10/80 /content/yolov5/21322100-1/test/images/dog_54_jpg.rf.1b3a36fc8f1cef43cbfb1ebcfae0b392.jpg: 416x416 1 Person, 9.4ms\n",
            "image 11/80 /content/yolov5/21322100-1/test/images/dog_78_jpg.rf.ad78df5fa2fd9e1cbc3c25b3907e0a9b.jpg: 416x416 2 Dogs, 9.4ms\n",
            "image 12/80 /content/yolov5/21322100-1/test/images/dusan-veverkolog-ETsFvMEBKTw-unsplash_jpg.rf.af46abd924bba409482c8f8a970a657b.jpg: 416x416 1 Bear, 10.5ms\n",
            "image 13/80 /content/yolov5/21322100-1/test/images/eliott-reyna-jCEpN62oWL4-unsplash_jpg.rf.85cf78c4e4b34303947ea3f5a55039b5.jpg: 416x416 6 Persons, 9.7ms\n",
            "image 14/80 /content/yolov5/21322100-1/test/images/ellicia-IgdVdJCmzf4-unsplash_jpg.rf.f8b8e140b5b4362d1c6afd8af8ca885c.jpg: 416x416 1 Bear, 2 Pigs, 9.8ms\n",
            "image 15/80 /content/yolov5/21322100-1/test/images/flouffy-7hEXd9kYPCY-unsplash_jpg.rf.a8496866dd6f4e7c9494453c445e33f0.jpg: 416x416 1 Dog, 9.3ms\n",
            "image 16/80 /content/yolov5/21322100-1/test/images/gemma-chua-tran-Ftvf4VbVbDE-unsplash_jpg.rf.63e45ca610945c605433fc3c62f05d39.jpg: 416x416 1 Person, 9.7ms\n",
            "image 17/80 /content/yolov5/21322100-1/test/images/hadis-safari-A7rkoSFjrG0-unsplash_jpg.rf.038cd34896f4536d51ba7153fd30a1ea.jpg: 416x416 1 Person, 9.2ms\n",
            "image 18/80 /content/yolov5/21322100-1/test/images/hans-jurgen-mager-Opd59VdnPn0-unsplash_jpg.rf.ed5bde8aeb9e894e8cad33fc1a49fc39.jpg: 416x416 1 Bear, 1 Dog, 8.7ms\n",
            "image 19/80 /content/yolov5/21322100-1/test/images/hyunwon-jang-LYK3ksSQyeo-unsplash_jpg.rf.a8919fed6bf75b009fc84f0547611195.jpg: 416x416 1 Dog, 1 Person, 8.9ms\n",
            "image 20/80 /content/yolov5/21322100-1/test/images/ilse-orsel-vmFEBIEz0hQ-unsplash_jpg.rf.9a4736f9b1cbb244633fc01cdbaefa97.jpg: 416x416 2 Cats, 8.8ms\n",
            "image 21/80 /content/yolov5/21322100-1/test/images/jean-wimmerlin-Ypv-kNjcnDA-unsplash_jpg.rf.060e85699e4fd10c87b7f10d049fe6e0.jpg: 416x416 1 Elephant, 8.7ms\n",
            "image 22/80 /content/yolov5/21322100-1/test/images/jessica-weiller-kZ8dyUT0h30-unsplash_jpg.rf.65afe9638114a15a988fdf9fba189ebe.jpg: 416x416 1 Bear, 9.1ms\n",
            "image 23/80 /content/yolov5/21322100-1/test/images/john-matychuk-jDRTl-w5jtY-unsplash_jpg.rf.fbdb07d243626a7899f43d071075ddda.jpg: 416x416 3 Elephants, 8.5ms\n",
            "image 24/80 /content/yolov5/21322100-1/test/images/jonny-gios-VYQRj0e54u8-unsplash_jpg.rf.19004b6dc593345d2a6481bffc2502c1.jpg: 416x416 1 Chicken, 8.9ms\n",
            "image 25/80 /content/yolov5/21322100-1/test/images/jopeel-quimpo-FBkgT8Y4mLw-unsplash_jpg.rf.8701dc5143cec5bf1fe8ef960b3c22c7.jpg: 416x416 1 Chicken, 8.7ms\n",
            "image 26/80 /content/yolov5/21322100-1/test/images/julien-mussard-OApeDBma_zY-unsplash_jpg.rf.34636742e0e2f7658b45716fa5a55c0d.jpg: 416x416 1 Bear, 8.4ms\n",
            "image 27/80 /content/yolov5/21322100-1/test/images/karsten-winegeart-BJaqPaH6AGQ-unsplash_jpg.rf.ea5123803ee66bcfb6d5af91b4f3ab09.jpg: 416x416 1 Dog, 9.0ms\n",
            "image 28/80 /content/yolov5/21322100-1/test/images/karsten-winegeart-Qb7D1xw28Co-unsplash_jpg.rf.34ca61d415ab0d4f6c01362740a16f24.jpg: 416x416 1 Dog, 9.6ms\n",
            "image 29/80 /content/yolov5/21322100-1/test/images/kelly-e1u0YdAkh9k-unsplash_jpg.rf.d84194b06560ea492b4582fff3d1c6c8.jpg: 416x416 2 Dogs, 8.6ms\n",
            "image 30/80 /content/yolov5/21322100-1/test/images/kote-puerto-so5nsYDOdxw-unsplash_jpg.rf.7d4c38c695002b8bea91a1f21c49c7cb.jpg: 416x416 3 Cats, 15.9ms\n",
            "image 31/80 /content/yolov5/21322100-1/test/images/kyle-mackie-rIo3D0hnVAg-unsplash_jpg.rf.88df4905f1f61c06316768032fb4b96d.jpg: 416x416 6 Cattles, 9.7ms\n",
            "image 32/80 /content/yolov5/21322100-1/test/images/larry-costales-Ahf1ZmcKzgE-unsplash_jpg.rf.f88335097ce2201a2f6e9565a8af896e.jpg: 416x416 1 Cattle, 8.7ms\n",
            "image 33/80 /content/yolov5/21322100-1/test/images/lucrezia-carnelos-0liYTl4dJxk-unsplash_jpg.rf.cf22ce3ee73643410b07c3635759d3fb.jpg: 416x416 1 Cat, 1 Dog, 8.6ms\n",
            "image 34/80 /content/yolov5/21322100-1/test/images/marek-piwnicki-PUVVsYJPh78-unsplash_jpg.rf.95ffaf9cb2945205312a35af01625b35.jpg: 416x416 3 Pigs, 8.7ms\n",
            "image 35/80 /content/yolov5/21322100-1/test/images/mathilda-khoo-vLR0YP_otCo-unsplash_jpg.rf.7bec4a1e035e73be9aad36d2e88274ef.jpg: 416x416 1 Person, 8.7ms\n",
            "image 36/80 /content/yolov5/21322100-1/test/images/matt-quinn-Q6-jv031muY-unsplash_jpg.rf.179e1cd8437e5355a5b5e8fa26e5030a.jpg: 416x416 12 Persons, 11.6ms\n",
            "image 37/80 /content/yolov5/21322100-1/test/images/matthew-spiteri-WfZ4WCuNtlg-unsplash_jpg.rf.00207cbec5f3067895bcb1b49d94e5f6.jpg: 416x416 3 Elephants, 8.8ms\n",
            "image 38/80 /content/yolov5/21322100-1/test/images/max-saeling-s3fOyTAOUUU-unsplash_jpg.rf.d06382cd7eb136b2b53bf16a3e60674c.jpg: 416x416 6 Cattles, 8.5ms\n",
            "image 39/80 /content/yolov5/21322100-1/test/images/megan-soule-xbVIg4Sjkc4-unsplash_jpg.rf.7540f4b60d6adf71e6642197813b3eb1.jpg: 416x416 1 Elephant, 2 Persons, 8.6ms\n",
            "image 40/80 /content/yolov5/21322100-1/test/images/milk-tea-h7Dw2hF4e0A-unsplash_jpg.rf.55c72d4095796f4440d1bacd0d3acdfc.jpg: 416x416 1 Cat, 8.4ms\n",
            "image 41/80 /content/yolov5/21322100-1/test/images/mohammed-alzubidi-TZVYwkLDX1E-unsplash_jpg.rf.274795cac21b991d65cf1aeec8cdf140.jpg: 416x416 1 Cattle, 8.7ms\n",
            "image 42/80 /content/yolov5/21322100-1/test/images/nadi-whatisdelirium-fZ8uf_L52wg-unsplash_jpg.rf.048d91d1121171ef2a78fa7b4349315c.jpg: 416x416 (no detections), 12.5ms\n",
            "image 43/80 /content/yolov5/21322100-1/test/images/nebojsa-ilic-w7QGY1ZNFds-unsplash_jpg.rf.229e1cd848bf6810a265b13bba366b41.jpg: 416x416 2 Pigs, 9.2ms\n",
            "image 44/80 /content/yolov5/21322100-1/test/images/nicholas-green-nPz8akkUmDI-unsplash_jpg.rf.2b4141706259f43bbf4accdbbdc3eba2.jpg: 416x416 7 Persons, 9.4ms\n",
            "image 45/80 /content/yolov5/21322100-1/test/images/omar-lopez-T6zu4jFhVwg-unsplash_jpg.rf.abc4f162f20d153a3e748a820de7071c.jpg: 416x416 12 Persons, 9.2ms\n",
            "image 46/80 /content/yolov5/21322100-1/test/images/patrick-pahlke-21iYB5pAtGg-unsplash_jpg.rf.f196ba531f0d1ce2ce1772f622b549ff.jpg: 416x416 1 Chicken, 1 Pig, 10.7ms\n",
            "image 47/80 /content/yolov5/21322100-1/test/images/paul-szewczyk-fHLqRr2b7CU-unsplash_jpg.rf.499fa608f23bf63bc4607f3389fc19e9.jpg: 416x416 3 Cattles, 13.2ms\n",
            "image 48/80 /content/yolov5/21322100-1/test/images/qijin-xu-vQUXUHjyy8A-unsplash_jpg.rf.d02d785f40f429792840b65013c0c3f1.jpg: 416x416 1 Dog, 1 Person, 9.7ms\n",
            "image 49/80 /content/yolov5/21322100-1/test/images/raoul-droog-yMSecCHsIBc-unsplash_jpg.rf.1e1eab32da5bb356bed168df04ebc50a.jpg: 416x416 1 Elephant, 10.1ms\n",
            "image 50/80 /content/yolov5/21322100-1/test/images/remi-remino-E9kVmtiqqGE-unsplash_jpg.rf.9957264ed9e9f54b91fa812531c34a43.jpg: 416x416 1 Cat, 9.7ms\n",
            "image 51/80 /content/yolov5/21322100-1/test/images/richard-jacobs-8oenpCXktqQ-unsplash_jpg.rf.99981c1a76d2a00973e87c335f8f1d94.jpg: 416x416 2 Elephants, 1 Person, 10.4ms\n",
            "image 52/80 /content/yolov5/21322100-1/test/images/robert-bottman-IZiAUsTFZm4-unsplash_jpg.rf.4fbe21dc3012eeac9f5ef50595d78585.jpg: 416x416 2 Chickens, 1 Person, 10.2ms\n",
            "image 53/80 /content/yolov5/21322100-1/test/images/roberto-nickson-udjuFffdtWY-unsplash_jpg.rf.8aa467ddf1f21d0899c5ef324be28d5d.jpg: 416x416 1 Pig, 10.0ms\n",
            "image 54/80 /content/yolov5/21322100-1/test/images/sarah-halliday-IuaPUiQotdU-unsplash_jpg.rf.2f2942d90f2e537a3d9408bb37043caf.jpg: 416x416 1 Chicken, 9.8ms\n",
            "image 55/80 /content/yolov5/21322100-1/test/images/senjuti-kundu-JfolIjRnveY-unsplash_jpg.rf.42129051d455c3091b13c0b5b2ffcf28.jpg: 416x416 1 Chicken, 12.9ms\n",
            "image 56/80 /content/yolov5/21322100-1/test/images/serge-le-strat-g3QTR9n7hsg-unsplash_jpg.rf.51ade13804e100d75ad13e6d470d5f09.jpg: 416x416 4 Cattles, 9.8ms\n",
            "image 57/80 /content/yolov5/21322100-1/test/images/sergio-ortega-7ce10LAA9HE-unsplash_jpg.rf.e6a3d93e5bf79e685315d060079c426d.jpg: 416x416 4 Cattles, 3 Elephants, 16.2ms\n",
            "image 58/80 /content/yolov5/21322100-1/test/images/sherard-campbell-Mzy3CT69Tns-unsplash_jpg.rf.6241ed00c834de63e543a32c63efe3c4.jpg: 416x416 1 Dog, 10.4ms\n",
            "image 59/80 /content/yolov5/21322100-1/test/images/sherard-campbell-OmF9_5i2muo-unsplash_jpg.rf.234707d4c701a6de760e15a4a002714d.jpg: 416x416 1 Pig, 11.8ms\n",
            "image 60/80 /content/yolov5/21322100-1/test/images/sikes-photos-FBVWVwbR5-w-unsplash_jpg.rf.706e5d84785a6967e2d96def4f6da058.jpg: 416x416 4 Cattles, 10.2ms\n",
            "image 61/80 /content/yolov5/21322100-1/test/images/sinval-carvalho-jTnSTGeXvNs-unsplash_jpg.rf.2a61b4c6784e6af5278e5cfbb04ce5f6.jpg: 416x416 1 Bear, 9.9ms\n",
            "image 62/80 /content/yolov5/21322100-1/test/images/sippakorn-yamkasikorn-wWIK8hnESnY-unsplash_jpg.rf.3a7ae2b5d94df424ec40dd933b437943.jpg: 416x416 1 Chicken, 10.2ms\n",
            "image 63/80 /content/yolov5/21322100-1/test/images/steven-boesky-6GH00hMbjPI-unsplash_jpg.rf.9ce367e4f7f403c3226964d908e2fa9a.jpg: 416x416 1 Chicken, 9.7ms\n",
            "image 64/80 /content/yolov5/21322100-1/test/images/sutirta-budiman-Xm_d76KavOk-unsplash_jpg.rf.d59ccf57bce0a190ed7c42f697dea57c.jpg: 416x416 1 Elephant, 10.1ms\n",
            "image 65/80 /content/yolov5/21322100-1/test/images/taylor-kopel-WX4i1Jq_o0Y-unsplash_jpg.rf.d80441d39ead18e2bd6151cd64251c08.jpg: 416x416 1 Dog, 9.6ms\n",
            "image 66/80 /content/yolov5/21322100-1/test/images/thomas-iversen-4W8FgDVyUME-unsplash_jpg.rf.ae2543055732239de0f56a6f29bc2dd3.jpg: 416x416 3 Chickens, 15.3ms\n",
            "image 67/80 /content/yolov5/21322100-1/test/images/thomas-lipke-KCyLa5xkoic-unsplash_jpg.rf.b0c7adcaf92416bff963d33047fb755e.jpg: 416x416 1 Bear, 9.0ms\n",
            "image 68/80 /content/yolov5/21322100-1/test/images/thomas-m-evans-mg2ACzid4fY-unsplash_jpg.rf.4403978d83ed0121c1726265c2ded413.jpg: 416x416 1 Cattle, 1 Elephant, 8.7ms\n",
            "image 69/80 /content/yolov5/21322100-1/test/images/victor-grabarczyk-2pbnDRhXc6Q-unsplash_jpg.rf.d0d713f089fc2d68e8bb6ab824fc2ad2.jpg: 416x416 1 Dog, 1 Person, 8.7ms\n",
            "image 70/80 /content/yolov5/21322100-1/test/images/vito-natale-avMIDf1WPCg-unsplash_jpg.rf.7a7c9682ca2533f20e353c4168c72f95.jpg: 416x416 1 Pig, 8.3ms\n",
            "image 71/80 /content/yolov5/21322100-1/test/images/wade-austin-ellis-FtuJIuBbUhI-unsplash_jpg.rf.6254154ad3a51815990360325eb1e5fc.jpg: 416x416 1 Dog, 1 Person, 8.1ms\n",
            "image 72/80 /content/yolov5/21322100-1/test/images/will-h-mcmahan-jM73872dy4Y-unsplash_jpg.rf.4ae7091b3f5206dbf3c6a69662b4a7f4.jpg: 416x416 3 Chickens, 8.4ms\n",
            "image 73/80 /content/yolov5/21322100-1/test/images/will-shirley-sbyEMIcFx34-unsplash_jpg.rf.7cbb09cc12737472ff76615841296f12.jpg: 416x416 1 Elephant, 8.5ms\n",
            "image 74/80 /content/yolov5/21322100-1/test/images/wolfgang-hasselmann-2zSkt52ELsk-unsplash_jpg.rf.30a3eb81f174566a2a3483629dc90364.jpg: 416x416 3 Elephants, 8.1ms\n",
            "image 75/80 /content/yolov5/21322100-1/test/images/wolfgang-hasselmann-W99CE3hOKf4-unsplash_jpg.rf.303c42e0e8a3314f3ed6c3f8d5ef0c0e.jpg: 416x416 1 Cattle, 15.5ms\n",
            "image 76/80 /content/yolov5/21322100-1/test/images/zdenek-machacek-PK94wCeXdjA-unsplash_jpg.rf.8535e87495c0ed8635bc42acec03a1af.jpg: 416x416 1 Bear, 8.7ms\n",
            "image 77/80 /content/yolov5/21322100-1/test/images/zdenek-machacek-hztya2tQqB8-unsplash_jpg.rf.a15db390eae3413edbd1a95d7483611e.jpg: 416x416 1 Bear, 8.5ms\n",
            "image 78/80 /content/yolov5/21322100-1/test/images/zoe-gayah-jonker-uhnbTZC7N9k-unsplash_jpg.rf.ee89d0ecfa10903396497315414cff13.jpg: 416x416 1 Cat, 9.2ms\n",
            "image 79/80 /content/yolov5/21322100-1/test/images/zoe-schaeffer-gHAAa9U4a0k-unsplash_jpg.rf.f9acada6a41302e647e07683fb798b49.jpg: 416x416 1 Chicken, 9.3ms\n",
            "image 80/80 /content/yolov5/21322100-1/test/images/zoe-schaeffer-vpDQgn0npaU-unsplash_jpg.rf.56de7ab26c82d5ecda402fcfad75cb83.jpg: 416x416 1 Elephant, 1 Person, 9.4ms\n",
            "Speed: 0.4ms pre-process, 9.8ms inference, 1.1ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8dHcni6CJYt"
      },
      "source": [
        "# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}